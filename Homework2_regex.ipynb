{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BARUD77/Homework2/blob/main/Homework2_regex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e75c332d",
      "metadata": {
        "id": "e75c332d"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import tiktoken\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cloning repository and mounting drive"
      ],
      "metadata": {
        "id": "KybvBQGTJbLT"
      },
      "id": "KybvBQGTJbLT"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git -C Homework2 pull || git clone https://github.com/BARUD77/Homework2.git\n",
        "%cd Homework2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e75Vl6BRJa0r",
        "outputId": "e19aa7ee-d892-4043-9812-6fb0c9541c82"
      },
      "id": "e75Vl6BRJa0r",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: cannot change to 'Homework2': No such file or directory\n",
            "Cloning into 'Homework2'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 28 (delta 12), reused 19 (delta 7), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (28/28), 1.24 MiB | 28.93 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n",
            "/content/Homework2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ll"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK1-TgRZNlVr",
        "outputId": "79a67beb-1e20-45a8-818a-e128d4b9c2dc"
      },
      "id": "mK1-TgRZNlVr",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4688\n",
            "-rw-r--r-- 1 root    2775 Nov  4 09:54 artifact_simulation.py\n",
            "-rw-r--r-- 1 root 2851073 Nov  4 09:54 cleaned_text.txt\n",
            "-rw-r--r-- 1 root    1381 Nov  4 09:54 dataset.py\n",
            "-rw-r--r-- 1 root    6371 Nov  4 09:54 extract_sheet_changes.py\n",
            "-rw-r--r-- 1 root    8623 Nov  4 09:54 extract_txt.py\n",
            "-rw-r--r-- 1 root   10377 Nov  4 09:54 frame_extractor.py\n",
            "-rw-r--r-- 1 root   87694 Nov  4 09:54 Homework2.ipynb\n",
            "-rw-r--r-- 1 root   29002 Nov  4 09:54 Homework2_regex.ipynb\n",
            "-rw-r--r-- 1 root   94232 Nov  4 09:54 IFD_creation.ipynb\n",
            "-rw-r--r-- 1 root   32209 Nov  4 09:54 LLM_Homework_1_Hermon_Teklesenbet_100064487.ipynb\n",
            "-rw-r--r-- 1 root   91180 Nov  4 09:54 loss_plot.png\n",
            "-rw-r--r-- 1 root 1527298 Nov  4 09:54 merged_corpus.txt\n",
            "-rw-r--r-- 1 root    4928 Nov  4 09:54 model.py\n",
            "-rw-r--r-- 1 root    7763 Nov  4 09:54 train.py\n",
            "-rw-r--r-- 1 root    8860 Nov  4 09:54 Untitled-1.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5264777e",
      "metadata": {
        "id": "5264777e"
      },
      "source": [
        "# Loading the cleaned and merged text file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2396b616",
      "metadata": {
        "id": "2396b616"
      },
      "outputs": [],
      "source": [
        "with open(\"cleaned_text.txt\", \"r\") as f:\n",
        "    cleaned_text = f.read()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4a4d351",
      "metadata": {
        "id": "c4a4d351"
      },
      "source": [
        "# Tokenization with both regex and bpe tokenizers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6f7ae87",
      "metadata": {
        "id": "f6f7ae87"
      },
      "source": [
        "### Regex tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9c7a375f",
      "metadata": {
        "id": "9c7a375f"
      },
      "outputs": [],
      "source": [
        "class SimpleTokenizer:\n",
        "    def __init__(self, vocab):\n",
        "        self.tokens2ids = {tok: i for i, tok in enumerate(vocab)}\n",
        "        self.ids2tokens = {i: tok for tok, i in self.tokens2ids.items()}\n",
        "        self.unk_id = self.tokens2ids[\"<|unk|>\"]  # required\n",
        "\n",
        "    def encode(self, text):\n",
        "        tokens = re.split(r\"([.,:;?_!\\\"'()\\[\\]—\\-\\s])\", text)\n",
        "        tokens = [t.strip() for t in tokens if t and t.strip()]\n",
        "        return [self.tokens2ids.get(t, self.unk_id) for t in tokens]\n",
        "\n",
        "    def decode(self, ids):\n",
        "        text = \" \".join(self.ids2tokens[i] for i in ids)\n",
        "        return re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4e020846",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e020846",
        "outputId": "6c5c4a4d-0001-4b44-ce77-20cfc51b19cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size = 29916\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "# 0) (optional) clean non-printables to avoid odd tokens like '\\x001'\n",
        "def strip_nonprintable(s):\n",
        "    return ''.join(ch if unicodedata.category(ch)[0] != 'C' else ' ' for ch in s)\n",
        "\n",
        "cleaned_text = strip_nonprintable(cleaned_text)\n",
        "\n",
        "# 1) tokenize the corpus once to build the base vocab\n",
        "preprocessed = re.split(r\"([.,:;?_!\\\"'()\\[\\]—\\-\\s])\", cleaned_text)\n",
        "preprocessed = [t.strip() for t in preprocessed if t and t.strip()]\n",
        "\n",
        "# 2) build vocab set from corpus (no specials yet)\n",
        "base_vocab = set(preprocessed)\n",
        "\n",
        "# 3) add specials up front in a deterministic order\n",
        "specials = [\"<|pad|>\", \"<|bos|>\", \"<|eos|>\", \"<|unk|>\"]\n",
        "# exclude any duplicates of specials from the base set\n",
        "base_vocab -= set(specials)\n",
        "\n",
        "# 4) finalize the ordered vocab: specials first, then sorted tokens\n",
        "vocab = specials + sorted(base_vocab)\n",
        "vocab_size = len(vocab)\n",
        "print(\"Vocab size =\", vocab_size)\n",
        "\n",
        "# 5) construct the tokenizer with this *fixed* vocab\n",
        "regextokenizer = SimpleTokenizer(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "461dd3b6",
      "metadata": {
        "id": "461dd3b6"
      },
      "source": [
        "# Preparing the dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "147c78ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "147c78ab",
        "outputId": "4cb6ab01-93d8-4cf0-98c8-c9823cfe046c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters in the model (Millions): 131.175936\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from model import GPTModel\n",
        "\n",
        "gpt2=False\n",
        "vocab_size = vocab_size\n",
        "tokenizer = regextokenizer\n",
        "\n",
        "GPT_CONFIG = {\n",
        "\"vocab_size\": vocab_size, # Vocabulary size\n",
        "\"context_length\": 256, # Context length\n",
        "\"emb_dim\": 768, # Embedding dimension\n",
        "\"n_heads\": 12, # Number of attention heads\n",
        "\"n_layers\": 12, # Number of layers\n",
        "\"drop_rate\": 0.1, # Dropout rate\n",
        "\"qkv_bias\": False # Query-Key-Value bias\n",
        "}\n",
        "\n",
        "model = GPTModel(GPT_CONFIG)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total number of parameters in the model (Millions): {total_params/1_000_000}\")\n",
        "print(\"-\"*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "24483e88",
      "metadata": {
        "id": "24483e88"
      },
      "outputs": [],
      "source": [
        "from dataset import create_dataloader_v1\n",
        "# Train/validation ratio\n",
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(cleaned_text))\n",
        "train_data = cleaned_text[:split_idx]\n",
        "val_data = cleaned_text[split_idx:]\n",
        "\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = create_dataloader_v1(\n",
        "    train_data,\n",
        "    gpt2,\n",
        "    tokenizer,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG[\"context_length\"],\n",
        "    stride=GPT_CONFIG[\"context_length\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_loader = create_dataloader_v1(\n",
        "    val_data,\n",
        "    gpt2,\n",
        "    tokenizer,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG[\"context_length\"],\n",
        "    stride=GPT_CONFIG[\"context_length\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "421200a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "421200a5",
        "outputId": "690f4925-57b1-4835-9821-af676d8b77ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Characters : 2506253\n",
            "Train Tokens : 537969\n",
            "====================================================================================================\n",
            "Validation Characters: 278473\n",
            "Validation Tokens: 61105\n",
            "====================================================================================================\n",
            "Train loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "====================================================================================================\n",
            "\n",
            "Validation loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ],
      "source": [
        "total_train_characters = len(train_data)\n",
        "total_train_tokens = len(tokenizer.encode(train_data))\n",
        "\n",
        "print(\"Train Characters :\", total_train_characters)\n",
        "print(\"Train Tokens :\", total_train_tokens)\n",
        "\n",
        "print(\"=\"*100)\n",
        "\n",
        "total_val_characters = len(val_data)\n",
        "total_val_tokens = len(tokenizer.encode(val_data))\n",
        "\n",
        "print(\"Validation Characters:\", total_val_characters)\n",
        "print(\"Validation Tokens:\", total_val_tokens)\n",
        "\n",
        "print(\"=\"*100)\n",
        "print(\"Train loader:\")\n",
        "for x, y in train_loader:\n",
        "    print(x.shape, y.shape)\n",
        "    break\n",
        "print(\"=\"*100)\n",
        "print(\"\\nValidation loader:\")\n",
        "for x, y in val_loader:\n",
        "    print(x.shape, y.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e7b9716",
      "metadata": {
        "id": "1e7b9716"
      },
      "source": [
        "# Pretraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4571e01b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4571e01b",
        "outputId": "32f242e2-dac8-42c4-8b6a-1f79962d7911"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train 9.569 | Val 9.512 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/best.pt\n",
            "Ep 1 (Step 000200): Train 6.546 | Val 5.602 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/best.pt\n",
            "Ep 1 (Step 000400): Train 6.361 | Val 5.403 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/best.pt\n",
            "Ep 1 (Step 000600): Train 5.814 | Val 5.220 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/best.pt\n",
            "Ep 1 (Step 000800): Train 5.237 | Val 5.182 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/best.pt\n",
            "Ep 1 (Step 001000): Train 5.161 | Val 5.098 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. Finally, we hope - 8B. This model on a dataset. 5. We develop the model is the model to ensure a set of DeepSeek - tune : A for the model. During a range of model is better, the context in the model\n",
            "Ep 2 (Step 001200): Train 5.350 | Val 5.039 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/best.pt\n",
            "Ep 2 (Step 001400): Train 5.523 | Val 5.000 | tokens 717,312\n",
            "  ↳ new best; saved to checkpoints/regex/best.pt\n",
            "Ep 2 (Step 001600): Train 5.211 | Val 4.899 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/best.pt\n",
            "Ep 2 (Step 001800): Train 4.801 | Val 4.812 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/best.pt\n",
            "Ep 2 (Step 002000): Train 5.630 | Val 4.773 | tokens 1,024,512\n",
            "  ↳ new best; saved to checkpoints/regex/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 - 4. To improve a large - v0. The data mix to solve the human - shot and a large resolution of the SFT models, and then improves is a wide range are capable, that it is a large - shot 0, such as we\n",
            "Ep 3 (Step 002200): Train 5.138 | Val 4.799 | tokens 1,126,912\n",
            "  ↳ no improvement (1/5)\n",
            "Ep 3 (Step 002400): Train 4.489 | Val 4.726 | tokens 1,229,312\n",
            "  ↳ new best; saved to checkpoints/regex/best.pt\n",
            "Ep 3 (Step 002600): Train 5.054 | Val 4.779 | tokens 1,331,712\n",
            "  ↳ no improvement (1/5)\n",
            "Ep 3 (Step 002800): Train 4.821 | Val 4.700 | tokens 1,434,112\n",
            "  ↳ new best; saved to checkpoints/regex/best.pt\n",
            "Ep 3 (Step 003000): Train 5.363 | Val 4.736 | tokens 1,536,512\n",
            "  ↳ no improvement (1/5)\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 175B can be been shown of Llama 3 405B Llama 3 performs GPT - 3 PaLM 62B of language model is still be able to the right and even here, when GPT - 3 70B on the limitations, we used for some - PaLM 540B 70B on both\n",
            "Ep 4 (Step 003200): Train 4.025 | Val 4.645 | tokens 1,638,912\n",
            "  ↳ new best; saved to checkpoints/regex/best.pt\n",
            "Ep 4 (Step 003400): Train 5.174 | Val 4.731 | tokens 1,741,312\n",
            "  ↳ no improvement (1/5)\n",
            "Ep 4 (Step 003600): Train 4.439 | Val 4.673 | tokens 1,843,712\n",
            "  ↳ no improvement (2/5)\n",
            "Ep 4 (Step 003800): Train 4.432 | Val 4.662 | tokens 1,946,112\n",
            "  ↳ no improvement (3/5)\n",
            "Ep 4 (Step 004000): Train 4.650 | Val 4.604 | tokens 2,048,512\n",
            "  ↳ new best; saved to checkpoints/regex/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 3. 5 3 3. 2.. 3 - 3 6 7 4. 12... 4. 3. 7... 6..... 2........ 71.... 1\n",
            "Ep 5 (Step 004200): Train 4.345 | Val 4.522 | tokens 2,150,912\n",
            "  ↳ new best; saved to checkpoints/regex/best.pt\n",
            "Ep 5 (Step 004400): Train 4.241 | Val 4.558 | tokens 2,253,312\n",
            "  ↳ no improvement (1/5)\n",
            "Ep 5 (Step 004600): Train 4.026 | Val 4.561 | tokens 2,355,712\n",
            "  ↳ no improvement (2/5)\n",
            "Ep 5 (Step 004800): Train 3.790 | Val 4.584 | tokens 2,458,112\n",
            "  ↳ no improvement (3/5)\n",
            "Ep 5 (Step 005000): Train 3.724 | Val 4.527 | tokens 2,560,512\n",
            "  ↳ no improvement (4/5)\n",
            "Ep 5 (Step 005200): Train 4.231 | Val 4.504 | tokens 2,662,912\n",
            "  ↳ new best; saved to checkpoints/regex/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 model with the same. 4 - 3. 5 and Claude 3. 2. Additionally, we develop GPT - 4o and GPT - 3 on reasoning benchmarks and GPT - 4o [ 124 ] [ 57 ] [ 65 ] - 3 405B – – – –\n",
            "Ep 6 (Step 005400): Train 4.194 | Val 4.515 | tokens 2,765,312\n",
            "  ↳ no improvement (1/5)\n",
            "Ep 6 (Step 005600): Train 3.816 | Val 4.500 | tokens 2,867,712\n",
            "  ↳ new best; saved to checkpoints/regex/best.pt\n",
            "Ep 6 (Step 005800): Train 3.988 | Val 4.489 | tokens 2,970,112\n",
            "  ↳ new best; saved to checkpoints/regex/best.pt\n",
            "Ep 6 (Step 006000): Train 3.678 | Val 4.484 | tokens 3,072,512\n",
            "  ↳ new best; saved to checkpoints/regex/best.pt\n",
            "Ep 6 (Step 006200): Train 3.470 | Val 4.481 | tokens 3,174,912\n",
            "  ↳ new best; saved to checkpoints/regex/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 5. 1. 5 - 3. 1. 7B Instruct, 8. 5 8 on top - 4 GPT - 3 achieves fewer than all benchmarks. For GPT - 5, GPT - 4o and Claude 3 achieves comparable to the performance on tasks.\n",
            "Ep 7 (Step 006400): Train 4.145 | Val 4.495 | tokens 3,277,312\n",
            "  ↳ no improvement (1/5)\n",
            "Ep 7 (Step 006600): Train 3.982 | Val 4.536 | tokens 3,379,712\n",
            "  ↳ no improvement (2/5)\n",
            "Ep 7 (Step 006800): Train 4.033 | Val 4.517 | tokens 3,482,112\n",
            "  ↳ no improvement (3/5)\n",
            "Ep 7 (Step 007000): Train 3.378 | Val 4.493 | tokens 3,584,512\n",
            "  ↳ no improvement (4/5)\n",
            "Ep 7 (Step 007200): Train 3.506 | Val 4.476 | tokens 3,686,912\n",
            "  ↳ new best; saved to checkpoints/regex/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. To a range of training approach is evaluated on the ﬁrst up to the gap above out up to understand the accuracy( see Section 6, 2022) and the one - 130B to the model’s ability to model as a ﬁne - 3. 4.,\n",
            "Ep 8 (Step 007400): Train 3.856 | Val 4.486 | tokens 3,789,312\n",
            "  ↳ no improvement (1/5)\n",
            "Ep 8 (Step 007600): Train 3.981 | Val 4.496 | tokens 3,891,712\n",
            "  ↳ no improvement (2/5)\n",
            "Ep 8 (Step 007800): Train 3.823 | Val 4.485 | tokens 3,994,112\n",
            "  ↳ no improvement (3/5)\n",
            "Ep 8 (Step 008000): Train 3.280 | Val 4.479 | tokens 4,096,512\n",
            "  ↳ no improvement (4/5)\n",
            "Ep 8 (Step 008200): Train 3.747 | Val 4.471 | tokens 4,198,912\n",
            "  ↳ new best; saved to checkpoints/regex/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 3. 4. 0 Claude 3 8B 0. 6 8 6 GPT - 4 31. 8. 5 - 4o. 1. 5. 4 GPT - Instruct Chat - Turbo GPT - 4o - Instruct Chat - 4 86. 2. 7 64\n",
            "Ep 9 (Step 008400): Train 3.261 | Val 4.459 | tokens 4,301,312\n",
            "  ↳ new best; saved to checkpoints/regex/best.pt\n",
            "Ep 9 (Step 008600): Train 3.473 | Val 4.473 | tokens 4,403,712\n",
            "  ↳ no improvement (1/5)\n",
            "Ep 9 (Step 008800): Train 3.491 | Val 4.475 | tokens 4,506,112\n",
            "  ↳ no improvement (2/5)\n",
            "Ep 9 (Step 009000): Train 3.148 | Val 4.468 | tokens 4,608,512\n",
            "  ↳ no improvement (3/5)\n",
            "Ep 9 (Step 009200): Train 3.904 | Val 4.463 | tokens 4,710,912\n",
            "  ↳ no improvement (4/5)\n",
            "Ep 9 (Step 009400): Train 3.851 | Val 4.473 | tokens 4,813,312\n",
            "  ↳ no improvement (5/5)\n",
            "Early stopping triggered.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 5 - 4 Turbo for each batch size of magnitude at the original training stability and GPT - 4o to Claude - 4o to surpass its performance, we found that despite the model sizes. Furthermore, and GPT - 4 to Claude 3 - 4o to generate\n",
            "Loaded best model from checkpoints/regex/best.pt (val loss 4.459).\n"
          ]
        }
      ],
      "source": [
        "from train import train_model_simple\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=4e-4, weight_decay=0.1)\n",
        "\n",
        "# estimate a token budget: ~5 epochs worth\n",
        "B, T = next(iter(train_loader))[0].shape  # (B, T)\n",
        "tokens_per_epoch = len(train_loader) * B * T\n",
        "target_tokens = 30 * tokens_per_epoch\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, gpt2, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=30,                 # large cap; early stopping will stop earlier\n",
        "    eval_freq=200,                  # evaluate every N steps (tune to your speed)\n",
        "    eval_iter=5,\n",
        "    start_context=\"Finally, given the broad spectrum of capabilities displayed by GPT-3\",\n",
        "    tokenizer=tokenizer,\n",
        "    # early stopping knobs\n",
        "    early_stop=True, patience=5, min_delta=1e-3,\n",
        "    save_path=\"checkpoints/regex/best.pt\",\n",
        "    use_plateau_lr=True, lr_factor=0.5, lr_patience=2, min_lr=1e-5,\n",
        "    max_tokens_seen=target_tokens\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bad92f0c",
      "metadata": {
        "id": "bad92f0c"
      },
      "source": [
        "# Plotting training and validation losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1d54f854",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "1d54f854",
        "outputId": "60b84e6d-35c8-4bb7-cb04-096714887eea"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x450 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_losses(tokens_seen, train_losses, val_losses, save_path=None):\n",
        "    \"\"\"\n",
        "    tokens_seen: list from train_model_simple (logged at each eval)\n",
        "    train_losses, val_losses: same length as tokens_seen\n",
        "    \"\"\"\n",
        "    if not (len(tokens_seen) == len(train_losses) == len(val_losses)):\n",
        "        raise ValueError(\"tokens_seen, train_losses, val_losses must have same length\")\n",
        "\n",
        "    plt.figure(figsize=(7,4.5))\n",
        "    plt.plot(tokens_seen, train_losses, label=\"Train loss\")\n",
        "    plt.plot(tokens_seen, val_losses, label=\"Val loss\")\n",
        "    plt.xlabel(\"Tokens seen\")\n",
        "    plt.ylabel(\"Cross-entropy loss\")\n",
        "    plt.title(\"Training/Validation Loss vs Tokens\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=200)\n",
        "    plt.show()\n",
        "\n",
        "plot_losses(tokens_seen, train_losses, val_losses, save_path=\"loss_plot.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca240d21",
      "metadata": {
        "id": "ca240d21"
      },
      "source": [
        "# Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math, json, random, copy, os, time\n",
        "import torch\n",
        "from train import train_model_simple  # your training loop\n",
        "\n",
        "def make_model_and_optim(cfg, device, lr, weight_decay):\n",
        "    # IMPORTANT: re-init a fresh model & optimizer each trial\n",
        "    model = GPTModel({**cfg}).to(device)\n",
        "    optim = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay, betas=(0.9, 0.95))\n",
        "    return model, optim\n",
        "\n",
        "def sample_hparams():\n",
        "    # Log-uniform for LR\n",
        "    lr = 10 ** random.uniform(-5, -2.3)          # ~1e-5 .. 5e-3\n",
        "    wd = random.choice([0.0, 0.05, 0.1, 0.15])   # discrete choices are fine\n",
        "    lr_factor = random.uniform(0.3, 0.7)\n",
        "    lr_patience = random.choice([1, 2, 3])\n",
        "    patience = random.choice([3, 5, 7])\n",
        "    min_delta = random.choice([5e-4, 1e-3, 2e-3])\n",
        "    return dict(lr=lr, weight_decay=wd, lr_factor=lr_factor,\n",
        "                lr_patience=lr_patience, patience=patience, min_delta=min_delta)\n",
        "\n",
        "def run_trial(trial_id, base_cfg, device, token_budget_multiplier=6):\n",
        "    # keep trials short: a few epochs worth of tokens\n",
        "    B, T = next(iter(train_loader))[0].shape\n",
        "    tokens_per_epoch = len(train_loader) * B * T\n",
        "    max_tokens = token_budget_multiplier * tokens_per_epoch\n",
        "\n",
        "    hp = sample_hparams()\n",
        "    model, optimizer = make_model_and_optim(base_cfg, device, hp[\"lr\"], hp[\"weight_decay\"])\n",
        "    save_dir = f\"checkpoints/regex/trial_{trial_id}\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    save_path = os.path.join(save_dir, \"best.pt\")\n",
        "\n",
        "    train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "        model=model, gpt2=gpt2,\n",
        "        train_loader=train_loader, val_loader=val_loader,\n",
        "        optimizer=optimizer, device=device,\n",
        "        num_epochs=30,             # cap; early stop will end earlier\n",
        "        eval_freq=200, eval_iter=8,\n",
        "        start_context=\"Finally, given the broad spectrum of capabilities displayed by GPT-3\",\n",
        "        tokenizer=tokenizer,\n",
        "        early_stop=True, patience=hp[\"patience\"], min_delta=hp[\"min_delta\"],\n",
        "        save_path=save_path,\n",
        "        use_plateau_lr=True, lr_factor=hp[\"lr_factor\"], lr_patience=hp[\"lr_patience\"], min_lr=1e-5,\n",
        "        max_tokens_seen=max_tokens\n",
        "    )\n",
        "\n",
        "    best_val = min(val_losses) if val_losses else float(\"inf\")\n",
        "    result = {\n",
        "        \"trial_id\": trial_id,\n",
        "        **hp,\n",
        "        \"best_val\": best_val,\n",
        "        \"tokens_seen\": int(tokens_seen[-1]) if tokens_seen else 0,\n",
        "        \"save_path\": save_path\n",
        "    }\n",
        "    # free GPU mem between trials\n",
        "    del model, optimizer\n",
        "    torch.cuda.empty_cache()\n",
        "    return result\n",
        "\n",
        "# ---- run N trials ----\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "random.seed(123); torch.manual_seed(123)\n",
        "\n",
        "N_TRIALS = 30  # start small; increase if you have time/compute\n",
        "results = []\n",
        "for t in range(N_TRIALS):\n",
        "    res = run_trial(trial_id=t, base_cfg=GPT_CONFIG, device=device, token_budget_multiplier=4)\n",
        "    print(f\"[trial {t}] val={res['best_val']:.4f}  lr={res['lr']:.2e}  wd={res['weight_decay']}\")\n",
        "    results.append(res)\n",
        "\n",
        "# pick best\n",
        "results = sorted(results, key=lambda x: x[\"best_val\"])\n",
        "print(\"Best:\", results[0])\n",
        "with open(\"tuning_results.json\", \"w\") as f:\n",
        "    json.dump(results, f, indent=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5p2AkCfe8zX",
        "outputId": "6b3d0ca9-c4d5-4762-9501-5f41e017b974"
      },
      "id": "K5p2AkCfe8zX",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train 10.435 | Val 10.426 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_0/best.pt\n",
            "Ep 1 (Step 000200): Train 7.384 | Val 6.893 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_0/best.pt\n",
            "Ep 1 (Step 000400): Train 6.692 | Val 6.122 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_0/best.pt\n",
            "Ep 1 (Step 000600): Train 6.410 | Val 5.760 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_0/best.pt\n",
            "Ep 1 (Step 000800): Train 5.614 | Val 5.576 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_0/best.pt\n",
            "Ep 1 (Step 001000): Train 6.003 | Val 5.452 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_0/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 5 - 1. 5 - shot the model. For more. 5. 9. 6. 5. 4. 1. 0. 3. 2 : 0. 4. 5. 8 0 - shot. 4. 2 76., 0\n",
            "Ep 2 (Step 001200): Train 5.819 | Val 5.332 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_0/best.pt\n",
            "Ep 2 (Step 001400): Train 5.653 | Val 5.290 | tokens 717,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_0/best.pt\n",
            "Ep 2 (Step 001600): Train 5.866 | Val 5.207 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_0/best.pt\n",
            "Ep 2 (Step 001800): Train 5.559 | Val 5.146 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_0/best.pt\n",
            "Ep 2 (Step 002000): Train 6.004 | Val 5.115 | tokens 1,024,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_0/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 - 4. To improve the same generation and both the data, we introduce the human the - Instruct - shot 5 - 3. 3, 2024) benchmarks - V3), and few - art, we implement the first, as pre - based -\n",
            "Ep 3 (Step 002200): Train 5.668 | Val 5.057 | tokens 1,126,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_0/best.pt\n",
            "Ep 3 (Step 002400): Train 5.663 | Val 5.051 | tokens 1,229,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_0/best.pt\n",
            "Ep 3 (Step 002600): Train 6.032 | Val 5.050 | tokens 1,331,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_0/best.pt\n",
            "Ep 3 (Step 002800): Train 5.771 | Val 4.973 | tokens 1,434,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_0/best.pt\n",
            "Ep 3 (Step 003000): Train 6.227 | Val 4.935 | tokens 1,536,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_0/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 - 3 - quality than - 7B - shot 5 - - Instruct - 3 - level - 1. 9 - 32B - shot - 72B - Instruct - 4. 1. 5 - Instruct 5 - shot 1 63. 7 52. 5 - scale -\n",
            "Ep 4 (Step 003200): Train 5.254 | Val 4.916 | tokens 1,638,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_0/best.pt\n",
            "Ep 4 (Step 003400): Train 5.788 | Val 4.904 | tokens 1,741,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_0/best.pt\n",
            "Ep 4 (Step 003600): Train 5.188 | Val 4.855 | tokens 1,843,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_0/best.pt\n",
            "Ep 4 (Step 003800): Train 5.113 | Val 4.867 | tokens 1,946,112\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 4 (Step 004000): Train 5.576 | Val 4.826 | tokens 2,048,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_0/best.pt\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 - tuned models of DeepSeek - of model training data to - 72B - of DeepSeek - source models. 5 - 3 - 3 - Instruct( this Qwen2 - scale - V2 - Chat - the model, and training examples of text, and text - 1\n",
            "Loaded best model from checkpoints/regex/trial_0/best.pt (val loss 4.826).\n",
            "[trial 0] val=4.8255  lr=1.38e-05  wd=0.0\n",
            "Ep 1 (Step 000000): Train 9.955 | Val 9.897 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_1/best.pt\n",
            "Ep 1 (Step 000200): Train 5.864 | Val 5.512 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_1/best.pt\n",
            "Ep 1 (Step 000400): Train 5.198 | Val 5.176 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_1/best.pt\n",
            "Ep 1 (Step 000600): Train 5.745 | Val 5.073 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_1/best.pt\n",
            "Ep 1 (Step 000800): Train 5.338 | Val 5.006 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_1/best.pt\n",
            "Ep 1 (Step 001000): Train 5.334 | Val 4.920 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_1/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 5 with an open - 4 - 3( 5 - 72B - shot))). 1 - 7B - shot 1. 5 - 7B - Base 7 - V2 - Base Qwen2 - Chat - based on performance of - V3 - source models with an\n",
            "Ep 2 (Step 001200): Train 5.490 | Val 4.928 | tokens 614,912\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 2 (Step 001400): Train 5.166 | Val 4.836 | tokens 717,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_1/best.pt\n",
            "Ep 2 (Step 001600): Train 5.129 | Val 4.749 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_1/best.pt\n",
            "Ep 2 (Step 001800): Train 4.964 | Val 4.695 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_1/best.pt\n",
            "Ep 2 (Step 002000): Train 4.693 | Val 4.552 | tokens 1,024,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_1/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 5. 1. 5 - 1. 5. 7B - Pro( e.) on the - 4). 5 - 4. 3 is the two - bench 5, as it is the - 4 - following and the - shot tasks.\n",
            "Ep 3 (Step 002200): Train 4.327 | Val 4.541 | tokens 1,126,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_1/best.pt\n",
            "Ep 3 (Step 002400): Train 5.260 | Val 4.521 | tokens 1,229,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_1/best.pt\n",
            "Ep 3 (Step 002600): Train 4.229 | Val 4.528 | tokens 1,331,712\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 3 (Step 002800): Train 4.708 | Val 4.493 | tokens 1,434,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_1/best.pt\n",
            "Ep 3 (Step 003000): Train 4.565 | Val 4.416 | tokens 1,536,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_1/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. To a range of training approach have been an analysis in the training phase, we found that the model on a natural language model. Our prompt is that the model is a more examples are a larger model as a few - 3 : In this,\n",
            "Ep 4 (Step 003200): Train 4.668 | Val 4.411 | tokens 1,638,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_1/best.pt\n",
            "Ep 4 (Step 003400): Train 4.604 | Val 4.383 | tokens 1,741,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_1/best.pt\n",
            "Ep 4 (Step 003600): Train 4.372 | Val 4.346 | tokens 1,843,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_1/best.pt\n",
            "Ep 4 (Step 003800): Train 4.733 | Val 4.345 | tokens 1,946,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_1/best.pt\n",
            "Ep 4 (Step 004000): Train 4.246 | Val 4.311 | tokens 2,048,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_1/best.pt\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 3. 4 Claude 3 Claude 3 8B and GPT - context length and GPT - 3 models( OpenAI - 4o) : GPT - 4o( GPT - 3. 3. 5 GPT - 4o) and GPT - 3 on the GPT - 4o we\n",
            "Loaded best model from checkpoints/regex/trial_1/best.pt (val loss 4.311).\n",
            "[trial 1] val=4.3112  lr=1.06e-04  wd=0.1\n",
            "Ep 1 (Step 000000): Train 10.234 | Val 10.203 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_2/best.pt\n",
            "Ep 1 (Step 000200): Train 6.365 | Val 5.654 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_2/best.pt\n",
            "Ep 1 (Step 000400): Train 5.335 | Val 5.201 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_2/best.pt\n",
            "Ep 1 (Step 000600): Train 5.340 | Val 5.086 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_2/best.pt\n",
            "Ep 1 (Step 000800): Train 5.925 | Val 4.981 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_2/best.pt\n",
            "Ep 1 (Step 001000): Train 5.360 | Val 4.942 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_2/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 4 - 4. 1. 5 - shot 79. 8. 0. 2. 5 - Chat - trained 5 - 5 Flash - R1 - 3 - 3 18. 8 52. 7 - Sonnet - Hard on Gemma - shot - Instruct 72\n",
            "Ep 2 (Step 001200): Train 4.983 | Val 4.841 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_2/best.pt\n",
            "Ep 2 (Step 001400): Train 5.062 | Val 4.790 | tokens 717,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_2/best.pt\n",
            "Ep 2 (Step 001600): Train 5.328 | Val 4.765 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_2/best.pt\n",
            "Ep 2 (Step 001800): Train 5.062 | Val 4.676 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_2/best.pt\n",
            "Ep 2 (Step 002000): Train 5.357 | Val 4.630 | tokens 1,024,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_2/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 6. 0 - 3 4. 0. 0 - 1. 8 0 16 0. 0 0 74. 6 4 0 41. 0. 4 0 83. 0 39 0. 3 0 - 1. 0. 7 0 - 7 0\n",
            "Ep 3 (Step 002200): Train 5.225 | Val 4.601 | tokens 1,126,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_2/best.pt\n",
            "Ep 3 (Step 002400): Train 4.887 | Val 4.601 | tokens 1,229,312\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 3 (Step 002600): Train 4.959 | Val 4.515 | tokens 1,331,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_2/best.pt\n",
            "Ep 3 (Step 002800): Train 4.690 | Val 4.493 | tokens 1,434,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_2/best.pt\n",
            "Ep 3 (Step 003000): Train 4.686 | Val 4.521 | tokens 1,536,512\n",
            "  ↳ no improvement (1/3)\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 is a range of the LLM to answer as the pre - training is not trained in the model. To address the model and generate the model. We would be an LLM to a high - context window size between different layers( e. g.,\n",
            "Ep 4 (Step 003200): Train 4.581 | Val 4.480 | tokens 1,638,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_2/best.pt\n",
            "Ep 4 (Step 003400): Train 4.477 | Val 4.495 | tokens 1,741,312\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 4 (Step 003600): Train 4.649 | Val 4.463 | tokens 1,843,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_2/best.pt\n",
            "Ep 4 (Step 003800): Train 4.684 | Val 4.419 | tokens 1,946,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_2/best.pt\n",
            "Ep 4 (Step 004000): Train 4.212 | Val 4.401 | tokens 2,048,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_2/best.pt\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. Overall, GPT - 3( 3), and GPT - shot setting, GPT - 3. In the state - of - art SOTA, the - art open - art results, the - art results were in the - the - only tasks.\n",
            "Loaded best model from checkpoints/regex/trial_2/best.pt (val loss 4.401).\n",
            "[trial 2] val=4.4010  lr=8.14e-05  wd=0.1\n",
            "Ep 1 (Step 000000): Train 9.114 | Val 8.879 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_3/best.pt\n",
            "Ep 1 (Step 000200): Train 6.266 | Val 5.951 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_3/best.pt\n",
            "Ep 1 (Step 000400): Train 6.394 | Val 5.512 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_3/best.pt\n",
            "Ep 1 (Step 000600): Train 5.954 | Val 5.510 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_3/best.pt\n",
            "Ep 1 (Step 000800): Train 5.518 | Val 5.478 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_3/best.pt\n",
            "Ep 1 (Step 001000): Train 5.978 | Val 5.353 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_3/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. This. 2. 3% ]. 2., such of well. 3. 2., we follow our modeling to achieve a key training. 3, and more perform DeepSeek. 2. 4 - shot 2, we design - Instruct, which\n",
            "Ep 2 (Step 001200): Train 5.929 | Val 5.243 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_3/best.pt\n",
            "Ep 2 (Step 001400): Train 5.740 | Val 5.274 | tokens 717,312\n",
            "  ↳ no improvement (1/7)\n",
            "Ep 2 (Step 001600): Train 5.436 | Val 5.233 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_3/best.pt\n",
            "Ep 2 (Step 001800): Train 6.250 | Val 5.135 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_3/best.pt\n",
            "Ep 2 (Step 002000): Train 6.104 | Val 5.046 | tokens 1,024,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_3/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. To be not evaluate all was not not the prompt that the language training at the original training. In an of the same data performance in the performance to provide of more the model of the question the final - shot, and used model is be an\n",
            "Ep 3 (Step 002200): Train 5.887 | Val 5.199 | tokens 1,126,912\n",
            "  ↳ no improvement (1/7)\n",
            "Ep 3 (Step 002400): Train 6.247 | Val 5.122 | tokens 1,229,312\n",
            "  ↳ no improvement (2/7)\n",
            "Ep 3 (Step 002600): Train 5.538 | Val 5.143 | tokens 1,331,712\n",
            "  ↳ no improvement (3/7)\n",
            "Ep 3 (Step 002800): Train 5.749 | Val 5.012 | tokens 1,434,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_3/best.pt\n",
            "Ep 3 (Step 003000): Train 5.769 | Val 4.880 | tokens 1,536,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_3/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 8. 3. 1%. This model in various and text in addition as not used to support the pre - trained of both DeepSeek - source - of the model on our models, and video, we train the input in pre - quality model of\n",
            "Ep 4 (Step 003200): Train 5.302 | Val 4.901 | tokens 1,638,912\n",
            "  ↳ no improvement (1/7)\n",
            "Ep 4 (Step 003400): Train 5.480 | Val 4.862 | tokens 1,741,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_3/best.pt\n",
            "Ep 4 (Step 003600): Train 5.354 | Val 4.892 | tokens 1,843,712\n",
            "  ↳ no improvement (1/7)\n",
            "Ep 4 (Step 003800): Train 5.715 | Val 4.901 | tokens 1,946,112\n",
            "  ↳ no improvement (2/7)\n",
            "Ep 4 (Step 004000): Train 5.399 | Val 4.866 | tokens 2,048,512\n",
            "  ↳ no improvement (3/7)\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 - art the models and a pre - of a wide the same work is an not be used with the model and a wide a long - training, we are also do used of our two and a number of - level by a function of - quality\n",
            "Loaded best model from checkpoints/regex/trial_3/best.pt (val loss 4.862).\n",
            "[trial 3] val=4.8622  lr=1.23e-03  wd=0.15\n",
            "Ep 1 (Step 000000): Train 10.378 | Val 10.336 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_4/best.pt\n",
            "Ep 1 (Step 000200): Train 6.898 | Val 6.530 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_4/best.pt\n",
            "Ep 1 (Step 000400): Train 5.856 | Val 5.879 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_4/best.pt\n",
            "Ep 1 (Step 000600): Train 6.178 | Val 5.609 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_4/best.pt\n",
            "Ep 1 (Step 000800): Train 5.819 | Val 5.434 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_4/best.pt\n",
            "Ep 1 (Step 001000): Train 5.445 | Val 5.245 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_4/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. However, we, we use the Gemini 1. We only, we use the number of these models that and their - training on the training as tasks, with the new, we can be to the model’s, and the performance of our training and\n",
            "Ep 2 (Step 001200): Train 5.679 | Val 5.182 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_4/best.pt\n",
            "Ep 2 (Step 001400): Train 5.545 | Val 5.116 | tokens 717,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_4/best.pt\n",
            "Ep 2 (Step 001600): Train 5.947 | Val 5.075 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_4/best.pt\n",
            "Ep 2 (Step 001800): Train 5.351 | Val 5.035 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_4/best.pt\n",
            "Ep 2 (Step 002000): Train 5.497 | Val 5.002 | tokens 1,024,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_4/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3, we also - Chat for all the - the reasoning of visual and GPT - level, our - VL and coding of Qwen2 - 8B of the overall, and the LLM, and the model, 2024b, 2024a the training data, which on their human\n",
            "Ep 3 (Step 002200): Train 5.508 | Val 4.939 | tokens 1,126,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_4/best.pt\n",
            "Ep 3 (Step 002400): Train 5.264 | Val 4.899 | tokens 1,229,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_4/best.pt\n",
            "Ep 3 (Step 002600): Train 5.480 | Val 4.852 | tokens 1,331,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_4/best.pt\n",
            "Ep 3 (Step 002800): Train 6.157 | Val 4.837 | tokens 1,434,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_4/best.pt\n",
            "Ep 3 (Step 003000): Train 5.645 | Val 4.858 | tokens 1,536,512\n",
            "  ↳ no improvement (1/3)\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 5. 1. 1. 6. 2 80. 0. 6. 4 68. 1. 3 74. 3 3. 3 40. 3. 3. 6 75. 3. 40. 0. 5. 1 74. 9.\n",
            "Ep 4 (Step 003200): Train 5.433 | Val 4.812 | tokens 1,638,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_4/best.pt\n",
            "Ep 4 (Step 003400): Train 5.037 | Val 4.802 | tokens 1,741,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_4/best.pt\n",
            "Ep 4 (Step 003600): Train 5.508 | Val 4.766 | tokens 1,843,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_4/best.pt\n",
            "Ep 4 (Step 003800): Train 5.251 | Val 4.775 | tokens 1,946,112\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 4 (Step 004000): Train 5.357 | Val 4.759 | tokens 2,048,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_4/best.pt\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 3. 0. 0. 74. 7. 2. 3. 8 - 3 70. 6. 1. 2. 6. 2. 4. 4. 9. 7. 2 54. 3. 4 62. 2. 6.\n",
            "Loaded best model from checkpoints/regex/trial_4/best.pt (val loss 4.759).\n",
            "[trial 4] val=4.7587  lr=1.89e-05  wd=0.0\n",
            "Ep 1 (Step 000000): Train 10.195 | Val 10.064 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_5/best.pt\n",
            "Ep 1 (Step 000200): Train 6.424 | Val 5.803 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_5/best.pt\n",
            "Ep 1 (Step 000400): Train 6.098 | Val 5.324 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_5/best.pt\n",
            "Ep 1 (Step 000600): Train 5.769 | Val 5.195 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_5/best.pt\n",
            "Ep 1 (Step 000800): Train 5.359 | Val 5.013 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_5/best.pt\n",
            "Ep 1 (Step 001000): Train 5.065 | Val 4.954 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_5/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 to use of the model’s benchmarks, and a series of - Bench between the high - training benchmarks, and other of an Gemini 1, and human image, and safety evaluations, and video, the second of - of Qwen2. Figure 5 - source.\n",
            "Ep 2 (Step 001200): Train 5.378 | Val 4.846 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_5/best.pt\n",
            "Ep 2 (Step 001400): Train 4.995 | Val 4.937 | tokens 717,312\n",
            "  ↳ no improvement (1/5)\n",
            "Ep 2 (Step 001600): Train 5.239 | Val 4.813 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_5/best.pt\n",
            "Ep 2 (Step 001800): Train 5.115 | Val 4.769 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_5/best.pt\n",
            "Ep 2 (Step 002000): Train 5.248 | Val 4.686 | tokens 1,024,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_5/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3, but for both PaLM 2. 5 - 3. 3 achieves this benchmark, we provide an average( b) - context from these benchmarks, and a diverse text to the original, we show that Gemini 1. To address these models, DeepSeek -\n",
            "Ep 3 (Step 002200): Train 5.295 | Val 4.648 | tokens 1,126,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_5/best.pt\n",
            "Ep 3 (Step 002400): Train 4.564 | Val 4.598 | tokens 1,229,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_5/best.pt\n",
            "Ep 3 (Step 002600): Train 5.056 | Val 4.607 | tokens 1,331,712\n",
            "  ↳ no improvement (1/5)\n",
            "Ep 3 (Step 002800): Train 4.795 | Val 4.606 | tokens 1,434,112\n",
            "  ↳ no improvement (2/5)\n",
            "Ep 3 (Step 003000): Train 5.019 | Val 4.617 | tokens 1,536,512\n",
            "  ↳ no improvement (3/5)\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3( 2024). On top - 3), Qwen3 - 3. 5 - Base( EM) and video results in a few - V2 are used in the - 4 dataset. 1 - 70B( SFT) and post - 3 2 - 4 -\n",
            "Ep 4 (Step 003200): Train 4.381 | Val 4.532 | tokens 1,638,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_5/best.pt\n",
            "Ep 4 (Step 003400): Train 4.857 | Val 4.518 | tokens 1,741,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_5/best.pt\n",
            "Ep 4 (Step 003600): Train 4.918 | Val 4.503 | tokens 1,843,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_5/best.pt\n",
            "Ep 4 (Step 003800): Train 4.178 | Val 4.513 | tokens 1,946,112\n",
            "  ↳ no improvement (1/5)\n",
            "Ep 4 (Step 004000): Train 4.580 | Val 4.482 | tokens 2,048,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_5/best.pt\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. However, we will be the potential of two key areas and only trained on these benchmarks. 6. In Table 2 models, with the model. As shown on a few - 3. For example, we present a result, a high - of\n",
            "Loaded best model from checkpoints/regex/trial_5/best.pt (val loss 4.482).\n",
            "[trial 5] val=4.4822  lr=6.14e-05  wd=0.15\n",
            "Ep 1 (Step 000000): Train 10.943 | Val 9.999 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_6/best.pt\n",
            "Ep 1 (Step 000200): Train 6.321 | Val 5.796 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_6/best.pt\n",
            "Ep 1 (Step 000400): Train 6.539 | Val 5.667 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_6/best.pt\n",
            "Ep 1 (Step 000600): Train 6.149 | Val 5.556 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_6/best.pt\n",
            "Ep 1 (Step 000800): Train 6.178 | Val 5.555 | tokens 410,112\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 1 (Step 001000): Train 6.140 | Val 5.265 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_6/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3, we find used for its, we create shown a models. The 1. In the highest are be understand with all is the best, so to large ] or a best we observed on a same : We ask, as all model that more more\n",
            "Ep 2 (Step 001200): Train 6.355 | Val 5.255 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_6/best.pt\n",
            "Ep 2 (Step 001400): Train 5.797 | Val 5.260 | tokens 717,312\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 2 (Step 001600): Train 5.753 | Val 5.284 | tokens 819,712\n",
            "  ↳ no improvement (2/3)\n",
            "Ep 2 (Step 001800): Train 5.863 | Val 5.214 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_6/best.pt\n",
            "Ep 2 (Step 002000): Train 5.000 | Val 5.188 | tokens 1,024,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_6/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 and fine on the training.. In English( i - 4B) [ and video, not been used models and a model models for - of the full the question. In this to provide an a total are a new language model to the LLM -\n",
            "Ep 3 (Step 002200): Train 5.880 | Val 5.198 | tokens 1,126,912\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 3 (Step 002400): Train 5.729 | Val 5.201 | tokens 1,229,312\n",
            "  ↳ no improvement (2/3)\n",
            "Ep 3 (Step 002600): Train 5.788 | Val 5.042 | tokens 1,331,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_6/best.pt\n",
            "Ep 3 (Step 002800): Train 5.735 | Val 5.126 | tokens 1,434,112\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 3 (Step 003000): Train 5.574 | Val 5.158 | tokens 1,536,512\n",
            "  ↳ no improvement (2/3)\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 71. 5. 2. 2) 14. 3. 6 - 1. 4 - 4 18. 8. 0. 5 Flash 1. 2. 1. 2 28. 9 19. 5. 5. 1. For large - 1 0\n",
            "Ep 4 (Step 003200): Train 5.817 | Val 5.101 | tokens 1,638,912\n",
            "  ↳ no improvement (3/3)\n",
            "Early stopping triggered.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 2. This, we consider the model - art from model, and a significant, but model. 8. They models that models and few - based from the following, the results in two models can open - 340B. This model, using the\n",
            "Loaded best model from checkpoints/regex/trial_6/best.pt (val loss 5.042).\n",
            "[trial 6] val=5.0419  lr=1.19e-03  wd=0.1\n",
            "Ep 1 (Step 000000): Train 10.107 | Val 9.480 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_7/best.pt\n",
            "Ep 1 (Step 000200): Train 6.367 | Val 5.741 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_7/best.pt\n",
            "Ep 1 (Step 000400): Train 5.987 | Val 5.563 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_7/best.pt\n",
            "Ep 1 (Step 000600): Train 5.087 | Val 5.377 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_7/best.pt\n",
            "Ep 1 (Step 000800): Train 5.609 | Val 5.201 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_7/best.pt\n",
            "Ep 1 (Step 001000): Train 5.594 | Val 5.035 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_7/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 - VL, DeepSeek - V2 are found with Gemini 1). 1. The model. 3, and Gemini 1. 2. As Llama 3.. 3. 2%. As an benchmarks.. 3 4. 2. 2. 5. 2\n",
            "Ep 2 (Step 001200): Train 5.193 | Val 5.079 | tokens 614,912\n",
            "  ↳ no improvement (1/7)\n",
            "Ep 2 (Step 001400): Train 4.847 | Val 5.079 | tokens 717,312\n",
            "  ↳ no improvement (2/7)\n",
            "Ep 2 (Step 001600): Train 5.666 | Val 4.996 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_7/best.pt\n",
            "Ep 2 (Step 001800): Train 5.080 | Val 4.868 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_7/best.pt\n",
            "Ep 2 (Step 002000): Train 5.235 | Val 4.883 | tokens 1,024,512\n",
            "  ↳ no improvement (1/7)\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. This are not been. 5, we see the pre - of the target to better models : What a question - training of the model’s performance over the model to address - answer. 0. 2 - off - training......\n",
            "Ep 3 (Step 002200): Train 5.814 | Val 4.831 | tokens 1,126,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_7/best.pt\n",
            "Ep 3 (Step 002400): Train 5.230 | Val 4.803 | tokens 1,229,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_7/best.pt\n",
            "Ep 3 (Step 002600): Train 5.195 | Val 4.844 | tokens 1,331,712\n",
            "  ↳ no improvement (1/7)\n",
            "Ep 3 (Step 002800): Train 5.057 | Val 4.705 | tokens 1,434,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_7/best.pt\n",
            "Ep 3 (Step 003000): Train 5.353 | Val 4.870 | tokens 1,536,512\n",
            "  ↳ no improvement (1/7)\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3, and video. In order to reduce the model to be comparable to improve inference, we provide the model to further use cases and the language model, Qwen2. This dataset, and text, we do not use the model’s - VL - Instruct results of\n",
            "Ep 4 (Step 003200): Train 5.342 | Val 4.688 | tokens 1,638,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_7/best.pt\n",
            "Ep 4 (Step 003400): Train 4.904 | Val 4.703 | tokens 1,741,312\n",
            "  ↳ no improvement (1/7)\n",
            "Ep 4 (Step 003600): Train 5.418 | Val 4.680 | tokens 1,843,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_7/best.pt\n",
            "Ep 4 (Step 003800): Train 4.910 | Val 4.695 | tokens 1,946,112\n",
            "  ↳ no improvement (1/7)\n",
            "Ep 4 (Step 004000): Train 4.856 | Val 4.679 | tokens 2,048,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_7/best.pt\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3( Table. In reasoning is likely to a single - shot benchmark and( with the training was not in a few - shot learning., 2019 ; rather than GLM - shot settings. We also set( or one et al., 2024).\n",
            "Loaded best model from checkpoints/regex/trial_7/best.pt (val loss 4.679).\n",
            "[trial 7] val=4.6790  lr=5.30e-04  wd=0.1\n",
            "Ep 1 (Step 000000): Train 9.273 | Val 8.985 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_8/best.pt\n",
            "Ep 1 (Step 000200): Train 6.075 | Val 5.682 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_8/best.pt\n",
            "Ep 1 (Step 000400): Train 6.488 | Val 5.470 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_8/best.pt\n",
            "Ep 1 (Step 000600): Train 5.848 | Val 5.346 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_8/best.pt\n",
            "Ep 1 (Step 000800): Train 5.953 | Val 5.193 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_8/best.pt\n",
            "Ep 1 (Step 001000): Train 5.248 | Val 5.184 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_8/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3, the model in the benchmarks, and DeepSeek( 5.......................................\n",
            "Ep 2 (Step 001200): Train 5.762 | Val 5.091 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_8/best.pt\n",
            "Ep 2 (Step 001400): Train 5.286 | Val 5.149 | tokens 717,312\n",
            "  ↳ no improvement (1/5)\n",
            "Ep 2 (Step 001600): Train 6.126 | Val 5.040 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_8/best.pt\n",
            "Ep 2 (Step 001800): Train 5.379 | Val 4.841 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_8/best.pt\n",
            "Ep 2 (Step 002000): Train 5.147 | Val 4.966 | tokens 1,024,512\n",
            "  ↳ no improvement (1/5)\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 of this results used in a single, including audio. Moreover In addition of the same. More prompts across the input the most. At a model to generate multimodal pre - shot results. On the final to enhance and also continue in the best language language\n",
            "Ep 3 (Step 002200): Train 5.417 | Val 4.868 | tokens 1,126,912\n",
            "  ↳ no improvement (2/5)\n",
            "Ep 3 (Step 002400): Train 4.738 | Val 4.834 | tokens 1,229,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_8/best.pt\n",
            "Ep 3 (Step 002600): Train 4.889 | Val 4.699 | tokens 1,331,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_8/best.pt\n",
            "Ep 3 (Step 002800): Train 5.181 | Val 4.675 | tokens 1,434,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_8/best.pt\n",
            "Ep 3 (Step 003000): Train 4.815 | Val 4.672 | tokens 1,536,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_8/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 4.............. 1.... 1............................\n",
            "Ep 4 (Step 003200): Train 5.140 | Val 4.732 | tokens 1,638,912\n",
            "  ↳ no improvement (1/5)\n",
            "Ep 4 (Step 003400): Train 5.275 | Val 4.696 | tokens 1,741,312\n",
            "  ↳ no improvement (2/5)\n",
            "Ep 4 (Step 003600): Train 4.929 | Val 4.575 | tokens 1,843,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_8/best.pt\n",
            "Ep 4 (Step 003800): Train 5.046 | Val 4.576 | tokens 1,946,112\n",
            "  ↳ no improvement (1/5)\n",
            "Ep 4 (Step 004000): Train 4.825 | Val 4.568 | tokens 2,048,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_8/best.pt\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 5 - 4. 1 - 4 GPT - 3............. 1............... 2.........\n",
            "Loaded best model from checkpoints/regex/trial_8/best.pt (val loss 4.568).\n",
            "[trial 8] val=4.5683  lr=7.06e-04  wd=0.15\n",
            "Ep 1 (Step 000000): Train 10.383 | Val 10.313 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_9/best.pt\n",
            "Ep 1 (Step 000200): Train 7.345 | Val 7.042 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_9/best.pt\n",
            "Ep 1 (Step 000400): Train 6.884 | Val 6.172 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_9/best.pt\n",
            "Ep 1 (Step 000600): Train 6.410 | Val 5.873 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_9/best.pt\n",
            "Ep 1 (Step 000800): Train 5.989 | Val 5.659 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_9/best.pt\n",
            "Ep 1 (Step 001000): Train 6.394 | Val 5.490 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_9/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 9. 0. In in and\" on tasks. The of - 4. 1. 4 - 74. 4 0. 0. 0. 1. 1. - 3. 6. 6. 0 - shot. 5 - 80. 1\n",
            "Ep 2 (Step 001200): Train 5.898 | Val 5.358 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_9/best.pt\n",
            "Ep 2 (Step 001400): Train 6.032 | Val 5.350 | tokens 717,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_9/best.pt\n",
            "Ep 2 (Step 001600): Train 6.060 | Val 5.245 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_9/best.pt\n",
            "Ep 2 (Step 001800): Train 5.810 | Val 5.217 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_9/best.pt\n",
            "Ep 2 (Step 002000): Train 5.804 | Val 5.152 | tokens 1,024,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_9/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. The on the model, we use a 1. e. 5. For the model and performance in our training. 1. 1. 0. 0, and the model on the number of this is a more on the training evaluation of our models\n",
            "Ep 3 (Step 002200): Train 5.653 | Val 5.091 | tokens 1,126,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_9/best.pt\n",
            "Ep 3 (Step 002400): Train 5.468 | Val 5.029 | tokens 1,229,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_9/best.pt\n",
            "Ep 3 (Step 002600): Train 5.570 | Val 5.020 | tokens 1,331,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_9/best.pt\n",
            "Ep 3 (Step 002800): Train 5.625 | Val 4.998 | tokens 1,434,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_9/best.pt\n",
            "Ep 3 (Step 003000): Train 5.624 | Val 4.966 | tokens 1,536,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_9/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 - VL - training model is a small - shot language model and a diverse with training. 2 [ 80 ]. 2. We report the overall Qwen2. We use of an its reasoning. 5 Flash are further - language, and the other Gemini 1\n",
            "Ep 4 (Step 003200): Train 5.880 | Val 4.962 | tokens 1,638,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_9/best.pt\n",
            "Ep 4 (Step 003400): Train 5.426 | Val 4.916 | tokens 1,741,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_9/best.pt\n",
            "Ep 4 (Step 003600): Train 5.841 | Val 4.896 | tokens 1,843,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_9/best.pt\n",
            "Ep 4 (Step 003800): Train 5.328 | Val 4.868 | tokens 1,946,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_9/best.pt\n",
            "Ep 4 (Step 004000): Train 5.175 | Val 4.868 | tokens 2,048,512\n",
            "  ↳ no improvement (1/5)\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 1. 0. 9. 9 29. 6 1. 5 83. 8. 1 47. 7. 2. 2 46. 1. 0 32. 9 67. 1. 5. 3. 6 56. 3. 3. 2\n",
            "Loaded best model from checkpoints/regex/trial_9/best.pt (val loss 4.868).\n",
            "[trial 9] val=4.8676  lr=1.22e-05  wd=0.05\n",
            "Ep 1 (Step 000000): Train 10.230 | Val 10.266 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_10/best.pt\n",
            "Ep 1 (Step 000200): Train 6.414 | Val 5.781 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_10/best.pt\n",
            "Ep 1 (Step 000400): Train 5.903 | Val 5.533 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_10/best.pt\n",
            "Ep 1 (Step 000600): Train 5.742 | Val 5.249 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_10/best.pt\n",
            "Ep 1 (Step 000800): Train 5.571 | Val 5.105 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_10/best.pt\n",
            "Ep 1 (Step 001000): Train 5.868 | Val 4.993 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_10/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 - grained - training data. 5 - 3. 5 - - shot 6. 8. 5. 0 - - 2. 4. 4. 5. 1. 1. 5 Pro. 7. 3. 6. 3 51. 5. 2\n",
            "Ep 2 (Step 001200): Train 5.810 | Val 4.893 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_10/best.pt\n",
            "Ep 2 (Step 001400): Train 5.284 | Val 4.795 | tokens 717,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_10/best.pt\n",
            "Ep 2 (Step 001600): Train 5.329 | Val 4.801 | tokens 819,712\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 2 (Step 001800): Train 5.125 | Val 4.773 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_10/best.pt\n",
            "Ep 2 (Step 002000): Train 5.219 | Val 4.740 | tokens 1,024,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_10/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 - training and task to the - training data from the performance of the evaluation of - training can generate the reward model using the performance of benchmarks. For the Qwen2 - shot setting, we report the vision - training data is a model, and audio and\n",
            "Ep 3 (Step 002200): Train 5.260 | Val 4.713 | tokens 1,126,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_10/best.pt\n",
            "Ep 3 (Step 002400): Train 5.263 | Val 4.682 | tokens 1,229,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_10/best.pt\n",
            "Ep 3 (Step 002600): Train 5.035 | Val 4.664 | tokens 1,331,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_10/best.pt\n",
            "Ep 3 (Step 002800): Train 5.606 | Val 4.607 | tokens 1,434,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_10/best.pt\n",
            "Ep 3 (Step 003000): Train 4.748 | Val 4.584 | tokens 1,536,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_10/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 - 3 - based on a set in our pre - 4, which also observe that Llama 2. We use of large language modeling. Finally, we conduct the model - to the model to the model context language model, we can be shown in the\n",
            "Ep 4 (Step 003200): Train 4.801 | Val 4.606 | tokens 1,638,912\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 4 (Step 003400): Train 4.551 | Val 4.547 | tokens 1,741,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_10/best.pt\n",
            "Ep 4 (Step 003600): Train 4.560 | Val 4.568 | tokens 1,843,712\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 4 (Step 003800): Train 4.250 | Val 4.521 | tokens 1,946,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_10/best.pt\n",
            "Ep 4 (Step 004000): Train 4.771 | Val 4.516 | tokens 2,048,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_10/best.pt\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 at that this section. For each other models, significantly outperforms PaLM 2 - 3 achieves a comprehensive significant performance across a broad by DeepSeek - 4o, each of multimodal tasks with a higher - art in both GPT - 3, DeepSeek - V3 has been significant\n",
            "Loaded best model from checkpoints/regex/trial_10/best.pt (val loss 4.516).\n",
            "[trial 10] val=4.5163  lr=5.09e-05  wd=0.1\n",
            "Ep 1 (Step 000000): Train 9.426 | Val 9.461 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_11/best.pt\n",
            "Ep 1 (Step 000200): Train 5.300 | Val 5.522 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_11/best.pt\n",
            "Ep 1 (Step 000400): Train 6.173 | Val 5.263 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_11/best.pt\n",
            "Ep 1 (Step 000600): Train 5.745 | Val 5.022 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_11/best.pt\n",
            "Ep 1 (Step 000800): Train 5.721 | Val 4.983 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_11/best.pt\n",
            "Ep 1 (Step 001000): Train 5.543 | Val 4.855 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_11/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. We evaluate the quality of the models to the reward models, our models to achieve in the model performance were presented in the Gemini 1. 5 Pro, and a question), we report of Gemini 1. 5 Flash on various models on the model\n",
            "Ep 2 (Step 001200): Train 5.256 | Val 4.825 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_11/best.pt\n",
            "Ep 2 (Step 001400): Train 5.002 | Val 4.674 | tokens 717,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_11/best.pt\n",
            "Ep 2 (Step 001600): Train 5.147 | Val 4.690 | tokens 819,712\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 2 (Step 001800): Train 4.872 | Val 4.633 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_11/best.pt\n",
            "Ep 2 (Step 002000): Train 5.082 | Val 4.571 | tokens 1,024,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_11/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 0. 8. 5. 1. 3. 4 0. 1 0. 9. 5. 5. 5. 7. 6 74. 0. 7. 5 51. 8 52. 8 8 49. 1 68. 7. 4\n",
            "Ep 3 (Step 002200): Train 4.986 | Val 4.553 | tokens 1,126,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_11/best.pt\n",
            "Ep 3 (Step 002400): Train 4.686 | Val 4.553 | tokens 1,229,312\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 3 (Step 002600): Train 4.437 | Val 4.457 | tokens 1,331,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_11/best.pt\n",
            "Ep 3 (Step 002800): Train 4.499 | Val 4.464 | tokens 1,434,112\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 3 (Step 003000): Train 4.525 | Val 4.372 | tokens 1,536,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_11/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 3 achieves a zero - shot setting, and few - shot learning [ 21 ], ], GPT - shot, few - 3 with the performance on the task, GPT - shot benchmarks, and few - shot, GPT - shot setting, the\n",
            "Ep 4 (Step 003200): Train 4.410 | Val 4.365 | tokens 1,638,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_11/best.pt\n",
            "Ep 4 (Step 003400): Train 4.413 | Val 4.338 | tokens 1,741,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_11/best.pt\n",
            "Ep 4 (Step 003600): Train 4.336 | Val 4.337 | tokens 1,843,712\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 4 (Step 003800): Train 4.373 | Val 4.289 | tokens 1,946,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_11/best.pt\n",
            "Ep 4 (Step 004000): Train 3.753 | Val 4.256 | tokens 2,048,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_11/best.pt\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 3. 5 76. 2 76 1 88. 63. 2 Qwen3 - 14B 63. 6B 46. 4. 3. 8 80. 7 Qwen3 - 6B 53. 8 65. 4 Qwen3 - 235B - 4B 26. 6 76. 3\n",
            "Loaded best model from checkpoints/regex/trial_11/best.pt (val loss 4.256).\n",
            "[trial 11] val=4.2557  lr=1.71e-04  wd=0.1\n",
            "Ep 1 (Step 000000): Train 10.101 | Val 10.130 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_12/best.pt\n",
            "Ep 1 (Step 000200): Train 6.348 | Val 5.572 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_12/best.pt\n",
            "Ep 1 (Step 000400): Train 6.052 | Val 5.256 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_12/best.pt\n",
            "Ep 1 (Step 000600): Train 5.106 | Val 5.063 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_12/best.pt\n",
            "Ep 1 (Step 000800): Train 5.347 | Val 4.962 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_12/best.pt\n",
            "Ep 1 (Step 001000): Train 5.399 | Val 4.876 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_12/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 3. 8% of the same model is often better by the model can be a context of model. 3 is the same large large model training process is a single - 2 - shot setting. The overall that is a multi - V3 data from the\n",
            "Ep 2 (Step 001200): Train 5.311 | Val 4.791 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_12/best.pt\n",
            "Ep 2 (Step 001400): Train 5.630 | Val 4.747 | tokens 717,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_12/best.pt\n",
            "Ep 2 (Step 001600): Train 5.445 | Val 4.707 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_12/best.pt\n",
            "Ep 2 (Step 001800): Train 5.446 | Val 4.682 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_12/best.pt\n",
            "Ep 2 (Step 002000): Train 4.965 | Val 4.601 | tokens 1,024,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_12/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 with the state - 3. 2. 2 1... 5. 6.. 5. 6. 7 67. 2. 6..... 2................\n",
            "Ep 3 (Step 002200): Train 4.812 | Val 4.564 | tokens 1,126,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_12/best.pt\n",
            "Ep 3 (Step 002400): Train 4.889 | Val 4.556 | tokens 1,229,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_12/best.pt\n",
            "Ep 3 (Step 002600): Train 4.960 | Val 4.523 | tokens 1,331,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_12/best.pt\n",
            "Ep 3 (Step 002800): Train 4.741 | Val 4.512 | tokens 1,434,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_12/best.pt\n",
            "Ep 3 (Step 003000): Train 4.770 | Val 4.471 | tokens 1,536,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_12/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 5 - 3. 3. 5 - 2. 1.. 1...................................\n",
            "Ep 4 (Step 003200): Train 4.620 | Val 4.448 | tokens 1,638,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_12/best.pt\n",
            "Ep 4 (Step 003400): Train 4.343 | Val 4.427 | tokens 1,741,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_12/best.pt\n",
            "Ep 4 (Step 003600): Train 4.223 | Val 4.414 | tokens 1,843,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_12/best.pt\n",
            "Ep 4 (Step 003800): Train 4.364 | Val 4.356 | tokens 1,946,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_12/best.pt\n",
            "Ep 4 (Step 004000): Train 4.623 | Val 4.359 | tokens 2,048,512\n",
            "  ↳ no improvement (1/7)\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 2. The few - shot examples were not only to this in the few - shot setting. We apply several languages are very large language pairs with human evaluation, such as question answering task that the results for GPT - shot performance on all benchmarks including\n",
            "Loaded best model from checkpoints/regex/trial_12/best.pt (val loss 4.356).\n",
            "[trial 12] val=4.3559  lr=9.58e-05  wd=0.1\n",
            "Ep 1 (Step 000000): Train 9.319 | Val 9.226 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_13/best.pt\n",
            "Ep 1 (Step 000200): Train 6.081 | Val 5.709 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_13/best.pt\n",
            "Ep 1 (Step 000400): Train 6.107 | Val 5.522 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_13/best.pt\n",
            "Ep 1 (Step 000600): Train 5.718 | Val 5.238 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_13/best.pt\n",
            "Ep 1 (Step 000800): Train 5.992 | Val 5.321 | tokens 410,112\n",
            "  ↳ no improvement (1/7)\n",
            "Ep 1 (Step 001000): Train 5.872 | Val 5.338 | tokens 512,512\n",
            "  ↳ no improvement (2/7)\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 using a series benchmarks :, including benchmarks. In DeepSeek - 1 - turn - grained have be the model’s and their only - 4 and even, we found... 3 - source that the speech 3’s to evaluate a text models and a time of\n",
            "Ep 2 (Step 001200): Train 5.940 | Val 5.336 | tokens 614,912\n",
            "  ↳ no improvement (3/7)\n",
            "Ep 2 (Step 001400): Train 5.780 | Val 5.198 | tokens 717,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_13/best.pt\n",
            "Ep 2 (Step 001600): Train 6.021 | Val 5.044 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_13/best.pt\n",
            "Ep 2 (Step 001800): Train 5.998 | Val 5.162 | tokens 922,112\n",
            "  ↳ no improvement (1/7)\n",
            "Ep 2 (Step 002000): Train 5.591 | Val 5.149 | tokens 1,024,512\n",
            "  ↳ no improvement (2/7)\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. To also final, we initialize - based to evaluate a more set is a comprehensive data. This image to be we observe in Table report human the model, we utilize the performance to our results the same to the model to minimize models can create that\n",
            "Ep 3 (Step 002200): Train 5.486 | Val 5.116 | tokens 1,126,912\n",
            "  ↳ no improvement (3/7)\n",
            "Ep 3 (Step 002400): Train 5.750 | Val 5.066 | tokens 1,229,312\n",
            "  ↳ no improvement (4/7)\n",
            "Ep 3 (Step 002600): Train 5.327 | Val 4.961 | tokens 1,331,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_13/best.pt\n",
            "Ep 3 (Step 002800): Train 5.776 | Val 4.936 | tokens 1,434,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_13/best.pt\n",
            "Ep 3 (Step 003000): Train 5.391 | Val 4.919 | tokens 1,536,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_13/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 - D. The same and high - training for a similar as each best. The language model - shot capabilities in the pre - 4 - context. 2% and more results of Qwen2. 5 - to the training for the Qwen3 - VL - 3.\n",
            "Ep 4 (Step 003200): Train 5.944 | Val 4.939 | tokens 1,638,912\n",
            "  ↳ no improvement (1/7)\n",
            "Ep 4 (Step 003400): Train 5.760 | Val 4.948 | tokens 1,741,312\n",
            "  ↳ no improvement (2/7)\n",
            "Ep 4 (Step 003600): Train 5.253 | Val 4.913 | tokens 1,843,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_13/best.pt\n",
            "Ep 4 (Step 003800): Train 5.478 | Val 4.839 | tokens 1,946,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_13/best.pt\n",
            "Ep 4 (Step 004000): Train 5.204 | Val 4.908 | tokens 2,048,512\n",
            "  ↳ no improvement (1/7)\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3, or evaluated with a given benchmarks, as the LLM learning. 1. 2 - Base 7B - 3, and additional models of the evaluation, we have a more stage, and the model - only in Table shot. We compare tasks, in the\n",
            "Loaded best model from checkpoints/regex/trial_13/best.pt (val loss 4.839).\n",
            "[trial 13] val=4.8392  lr=8.99e-04  wd=0.0\n",
            "Ep 1 (Step 000000): Train 10.217 | Val 10.210 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_14/best.pt\n",
            "Ep 1 (Step 000200): Train 6.733 | Val 5.906 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_14/best.pt\n",
            "Ep 1 (Step 000400): Train 5.991 | Val 5.562 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_14/best.pt\n",
            "Ep 1 (Step 000600): Train 5.951 | Val 5.313 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_14/best.pt\n",
            "Ep 1 (Step 000800): Train 5.832 | Val 5.133 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_14/best.pt\n",
            "Ep 1 (Step 001000): Train 5.684 | Val 5.045 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_14/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 1. Figure. 8%. 5.. 1..... 6..................... 4...........\n",
            "Ep 2 (Step 001200): Train 5.588 | Val 4.941 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_14/best.pt\n",
            "Ep 2 (Step 001400): Train 5.410 | Val 4.913 | tokens 717,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_14/best.pt\n",
            "Ep 2 (Step 001600): Train 5.489 | Val 4.818 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_14/best.pt\n",
            "Ep 2 (Step 001800): Train 5.251 | Val 4.790 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_14/best.pt\n",
            "Ep 2 (Step 002000): Train 4.767 | Val 4.793 | tokens 1,024,512\n",
            "  ↳ no improvement (1/7)\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 - shot performance when model and compare with these challenges and reasoning. We report results on the - attention with the model, of its performance across millions of tokens, Qwen2 - time of 0. 1. 2. 5 - turn benchmarks, and the video\n",
            "Ep 3 (Step 002200): Train 5.209 | Val 4.746 | tokens 1,126,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_14/best.pt\n",
            "Ep 3 (Step 002400): Train 5.092 | Val 4.749 | tokens 1,229,312\n",
            "  ↳ no improvement (1/7)\n",
            "Ep 3 (Step 002600): Train 4.887 | Val 4.659 | tokens 1,331,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_14/best.pt\n",
            "Ep 3 (Step 002800): Train 5.233 | Val 4.645 | tokens 1,434,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_14/best.pt\n",
            "Ep 3 (Step 003000): Train 5.246 | Val 4.634 | tokens 1,536,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_14/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 is the evaluation of the text - of the model is a smaller model, such as an example. The Qwen2. 5 - 3. 5 - 2 is the - shot setting. 5, we evaluate the model that the few - level with previous in\n",
            "Ep 4 (Step 003200): Train 4.763 | Val 4.650 | tokens 1,638,912\n",
            "  ↳ no improvement (1/7)\n",
            "Ep 4 (Step 003400): Train 5.075 | Val 4.618 | tokens 1,741,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_14/best.pt\n",
            "Ep 4 (Step 003600): Train 4.829 | Val 4.585 | tokens 1,843,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_14/best.pt\n",
            "Ep 4 (Step 003800): Train 4.761 | Val 4.577 | tokens 1,946,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_14/best.pt\n",
            "Ep 4 (Step 004000): Train 4.508 | Val 4.565 | tokens 2,048,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_14/best.pt\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 5. 6. 0 and the model to a significant results in the model size of the model to the models that the training framework, and the prompt. 3. 2. 3. 1. 1. 3. 1. 0 Ultra 3 We\n",
            "Loaded best model from checkpoints/regex/trial_14/best.pt (val loss 4.565).\n",
            "[trial 14] val=4.5646  lr=4.27e-05  wd=0.15\n",
            "Ep 1 (Step 000000): Train 9.932 | Val 9.696 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_15/best.pt\n",
            "Ep 1 (Step 000200): Train 6.286 | Val 5.636 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_15/best.pt\n",
            "Ep 1 (Step 000400): Train 5.642 | Val 5.323 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_15/best.pt\n",
            "Ep 1 (Step 000600): Train 5.532 | Val 5.178 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_15/best.pt\n",
            "Ep 1 (Step 000800): Train 5.533 | Val 4.932 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_15/best.pt\n",
            "Ep 1 (Step 001000): Train 5.395 | Val 4.961 | tokens 512,512\n",
            "  ↳ no improvement (1/5)\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 on the model’s training and use cases with both models. Moreover, we used in the model size of the model is used in English. Our benchmark performance of a set of each series, and safety context and for a combination of the total of each,\n",
            "Ep 2 (Step 001200): Train 5.203 | Val 4.748 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_15/best.pt\n",
            "Ep 2 (Step 001400): Train 5.125 | Val 4.813 | tokens 717,312\n",
            "  ↳ no improvement (1/5)\n",
            "Ep 2 (Step 001600): Train 5.166 | Val 4.734 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_15/best.pt\n",
            "Ep 2 (Step 001800): Train 4.823 | Val 4.705 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_15/best.pt\n",
            "Ep 2 (Step 002000): Train 5.084 | Val 4.631 | tokens 1,024,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_15/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 5 - 2. 3. 5 - 7B 1. 1. 0. 3 - Chat( 2) 48. 0. 8 74. 3. 3. 7. 5 66. 4 74. 0. 1. 8 31. 5.\n",
            "Ep 3 (Step 002200): Train 5.243 | Val 4.549 | tokens 1,126,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_15/best.pt\n",
            "Ep 3 (Step 002400): Train 4.963 | Val 4.552 | tokens 1,229,312\n",
            "  ↳ no improvement (1/5)\n",
            "Ep 3 (Step 002600): Train 4.558 | Val 4.508 | tokens 1,331,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_15/best.pt\n",
            "Ep 3 (Step 002800): Train 4.602 | Val 4.499 | tokens 1,434,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_15/best.pt\n",
            "Ep 3 (Step 003000): Train 4.442 | Val 4.483 | tokens 1,536,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_15/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 5. 4. 2. 1. 2. 4. 2 0. 1. 1 5. 60. 4 Turbo. 5 33. 8 7 77. 0. 7. 9. 2 33. 7. 4 86. 0. 01\n",
            "Ep 4 (Step 003200): Train 4.727 | Val 4.430 | tokens 1,638,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_15/best.pt\n",
            "Ep 4 (Step 003400): Train 4.420 | Val 4.404 | tokens 1,741,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_15/best.pt\n",
            "Ep 4 (Step 003600): Train 4.302 | Val 4.442 | tokens 1,843,712\n",
            "  ↳ no improvement (1/5)\n",
            "Ep 4 (Step 003800): Train 4.517 | Val 4.364 | tokens 1,946,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_15/best.pt\n",
            "Ep 4 (Step 004000): Train 4.677 | Val 4.376 | tokens 2,048,512\n",
            "  ↳ no improvement (1/5)\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 5 - Pro has not trained on a similar benchmark dataset, GPT - 4o( Section 5). Furthermore, there are also been a benchmark in comparison between a long context. The evaluation framework, and other capabilities of the model also have also achieve\n",
            "Loaded best model from checkpoints/regex/trial_15/best.pt (val loss 4.364).\n",
            "[trial 15] val=4.3644  lr=1.05e-04  wd=0.15\n",
            "Ep 1 (Step 000000): Train 10.412 | Val 10.384 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_16/best.pt\n",
            "Ep 1 (Step 000200): Train 7.642 | Val 7.059 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_16/best.pt\n",
            "Ep 1 (Step 000400): Train 7.082 | Val 6.288 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_16/best.pt\n",
            "Ep 1 (Step 000600): Train 6.246 | Val 5.948 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_16/best.pt\n",
            "Ep 1 (Step 000800): Train 6.297 | Val 5.719 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_16/best.pt\n",
            "Ep 1 (Step 001000): Train 5.638 | Val 5.544 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_16/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 : 1. This. 1. 7 3) and the most. 3. to PaLM. 2... 0. 0. 5. 0. 5. 9. 5 - context... 1. 2. 4. For..\n",
            "Ep 2 (Step 001200): Train 6.134 | Val 5.445 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_16/best.pt\n",
            "Ep 2 (Step 001400): Train 6.155 | Val 5.356 | tokens 717,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_16/best.pt\n",
            "Ep 2 (Step 001600): Train 5.987 | Val 5.316 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_16/best.pt\n",
            "Ep 2 (Step 001800): Train 5.947 | Val 5.255 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_16/best.pt\n",
            "Ep 2 (Step 002000): Train 5.774 | Val 5.188 | tokens 1,024,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_16/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 - context with performance of the training, we use text tasks. 5 - Coder - VL - quality. To a large - 2. 4. 6. 7%. 2. 6. 5. 4. 0. 7. 1. 2. 2\n",
            "Ep 3 (Step 002200): Train 5.287 | Val 5.156 | tokens 1,126,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_16/best.pt\n",
            "Ep 3 (Step 002400): Train 5.197 | Val 5.066 | tokens 1,229,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_16/best.pt\n",
            "Ep 3 (Step 002600): Train 5.938 | Val 5.046 | tokens 1,331,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_16/best.pt\n",
            "Ep 3 (Step 002800): Train 5.425 | Val 5.016 | tokens 1,434,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_16/best.pt\n",
            "Ep 3 (Step 003000): Train 5.829 | Val 4.996 | tokens 1,536,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_16/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 - shot with GPT - shot 0 - shot benchmarks, which. 5 - shot tasks. 5. 0. 2 77. 0. 1. 5 68. 0. 5 - 20. 0. 3 85. 7 76. 1. 1 72\n",
            "Ep 4 (Step 003200): Train 5.722 | Val 4.954 | tokens 1,638,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_16/best.pt\n",
            "Ep 4 (Step 003400): Train 5.433 | Val 4.937 | tokens 1,741,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_16/best.pt\n",
            "Ep 4 (Step 003600): Train 5.437 | Val 4.949 | tokens 1,843,712\n",
            "  ↳ no improvement (1/7)\n",
            "Ep 4 (Step 003800): Train 5.191 | Val 4.901 | tokens 1,946,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_16/best.pt\n",
            "Ep 4 (Step 004000): Train 5.154 | Val 4.890 | tokens 2,048,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_16/best.pt\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 2 - VL dataset and the vision - 7B, we believe that also evaluate the model. 2. 5. 7. 2. 4%. 4 - 7B - 3. 4 82. 5. 1 65. 3. 3. 0. 0\n",
            "Loaded best model from checkpoints/regex/trial_16/best.pt (val loss 4.890).\n",
            "[trial 16] val=4.8898  lr=1.14e-05  wd=0.1\n",
            "Ep 1 (Step 000000): Train 10.420 | Val 10.387 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_17/best.pt\n",
            "Ep 1 (Step 000200): Train 7.771 | Val 7.229 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_17/best.pt\n",
            "Ep 1 (Step 000400): Train 7.044 | Val 6.398 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_17/best.pt\n",
            "Ep 1 (Step 000600): Train 6.397 | Val 6.021 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_17/best.pt\n",
            "Ep 1 (Step 000800): Train 5.691 | Val 5.797 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_17/best.pt\n",
            "Ep 1 (Step 001000): Train 6.362 | Val 5.634 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_17/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3, and the the specific., and to( 3. 4., we, and to., and is this, and GPT - 3, and( In the results a from are and the text, 2020 benchmarks, and the, the training\n",
            "Ep 2 (Step 001200): Train 5.695 | Val 5.521 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_17/best.pt\n",
            "Ep 2 (Step 001400): Train 5.912 | Val 5.439 | tokens 717,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_17/best.pt\n",
            "Ep 2 (Step 001600): Train 6.185 | Val 5.355 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_17/best.pt\n",
            "Ep 2 (Step 001800): Train 5.962 | Val 5.304 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_17/best.pt\n",
            "Ep 2 (Step 002000): Train 5.778 | Val 5.227 | tokens 1,024,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_17/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 1. However in the final. 0% in( 6. 5 - 3) and Gemini 1. 2 4. 4. 6. 4. 1. 5. 7. 2 - VL. As. 0. 6. 10 of 65.\n",
            "Ep 3 (Step 002200): Train 5.482 | Val 5.194 | tokens 1,126,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_17/best.pt\n",
            "Ep 3 (Step 002400): Train 5.540 | Val 5.165 | tokens 1,229,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_17/best.pt\n",
            "Ep 3 (Step 002600): Train 5.815 | Val 5.119 | tokens 1,331,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_17/best.pt\n",
            "Ep 3 (Step 002800): Train 5.705 | Val 5.112 | tokens 1,434,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_17/best.pt\n",
            "Ep 3 (Step 003000): Train 5.713 | Val 5.059 | tokens 1,536,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_17/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 8 - shot 76. 0. 2. 8 69.. 9 77. 8. 3 54.. 5 - shot 35. 3. 8.......... 5.... 0...\n",
            "Ep 4 (Step 003200): Train 5.003 | Val 5.021 | tokens 1,638,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_17/best.pt\n",
            "Ep 4 (Step 003400): Train 5.570 | Val 5.038 | tokens 1,741,312\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 4 (Step 003600): Train 5.795 | Val 4.982 | tokens 1,843,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_17/best.pt\n",
            "Ep 4 (Step 003800): Train 5.686 | Val 4.981 | tokens 1,946,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_17/best.pt\n",
            "Ep 4 (Step 004000): Train 5.897 | Val 4.926 | tokens 2,048,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_17/best.pt\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 5 - 1 - 3. 5 3. 4 - shot 2 3. For 7. 5 - trained performance. 7 52. 0 - 72B - shot 28. 0 - 3 79. 5. 0 - 3 59. 8 57. 4\n",
            "Loaded best model from checkpoints/regex/trial_17/best.pt (val loss 4.926).\n",
            "[trial 17] val=4.9258  lr=1.00e-05  wd=0.0\n",
            "Ep 1 (Step 000000): Train 9.950 | Val 9.963 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_18/best.pt\n",
            "Ep 1 (Step 000200): Train 5.975 | Val 5.589 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_18/best.pt\n",
            "Ep 1 (Step 000400): Train 5.852 | Val 5.274 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_18/best.pt\n",
            "Ep 1 (Step 000600): Train 5.646 | Val 5.042 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_18/best.pt\n",
            "Ep 1 (Step 000800): Train 5.416 | Val 4.862 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_18/best.pt\n",
            "Ep 1 (Step 001000): Train 5.100 | Val 4.902 | tokens 512,512\n",
            "  ↳ no improvement (1/3)\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. The model and a comprehensive large - to the performance of - tuned the model sizes into a dataset this, we find of open - of data. The safety of the reward models, we compute. We then, we have used for the data of\n",
            "Ep 2 (Step 001200): Train 5.008 | Val 4.757 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_18/best.pt\n",
            "Ep 2 (Step 001400): Train 4.885 | Val 4.771 | tokens 717,312\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 2 (Step 001600): Train 4.883 | Val 4.690 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_18/best.pt\n",
            "Ep 2 (Step 001800): Train 5.011 | Val 4.607 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_18/best.pt\n",
            "Ep 2 (Step 002000): Train 4.998 | Val 4.512 | tokens 1,024,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_18/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 3. 7. 5 - 3 50. 2. 1, 7. 5. 3 2. 1 32 9 3 - 4 2 - 4 50. 3 7 1 64. 2 4 5 44. 3. 3 5 - 3. 5\n",
            "Ep 3 (Step 002200): Train 5.044 | Val 4.499 | tokens 1,126,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_18/best.pt\n",
            "Ep 3 (Step 002400): Train 4.525 | Val 4.537 | tokens 1,229,312\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 3 (Step 002600): Train 4.625 | Val 4.460 | tokens 1,331,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_18/best.pt\n",
            "Ep 3 (Step 002800): Train 4.333 | Val 4.392 | tokens 1,434,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_18/best.pt\n",
            "Ep 3 (Step 003000): Train 4.212 | Val 4.408 | tokens 1,536,512\n",
            "  ↳ no improvement (1/3)\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 1. 1... 5. 5 and Qwen2 - Turbo [ 43 ] include - – Instruct in - 4o [ 18 ], Claude - Pro [ 76 ], 80. 5 [ 48 ], 72, 35 ], – 82 ]\n",
            "Ep 4 (Step 003200): Train 4.330 | Val 4.330 | tokens 1,638,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_18/best.pt\n",
            "Ep 4 (Step 003400): Train 4.298 | Val 4.327 | tokens 1,741,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_18/best.pt\n",
            "Ep 4 (Step 003600): Train 4.032 | Val 4.408 | tokens 1,843,712\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 4 (Step 003800): Train 4.037 | Val 4.310 | tokens 1,946,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_18/best.pt\n",
            "Ep 4 (Step 004000): Train 3.749 | Val 4.286 | tokens 2,048,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_18/best.pt\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 5 - Turbo, and also shows consistent performance on tasks. 5 - Bench - shot learning, and competitive results. 3 are used in English and report results across a range of our evaluation framework. 5 - shot setting. 5 - shot and Claude\n",
            "Loaded best model from checkpoints/regex/trial_18/best.pt (val loss 4.286).\n",
            "[trial 18] val=4.2860  lr=1.48e-04  wd=0.0\n",
            "Ep 1 (Step 000000): Train 8.835 | Val 8.735 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_19/best.pt\n",
            "Ep 1 (Step 000200): Train 6.427 | Val 5.590 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_19/best.pt\n",
            "Ep 1 (Step 000400): Train 6.643 | Val 5.424 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_19/best.pt\n",
            "Ep 1 (Step 000600): Train 6.121 | Val 5.361 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_19/best.pt\n",
            "Ep 1 (Step 000800): Train 5.795 | Val 5.273 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_19/best.pt\n",
            "Ep 1 (Step 001000): Train 5.919 | Val 5.304 | tokens 512,512\n",
            "  ↳ no improvement (1/5)\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 - 4 - 4 - 3 - 3 - 3. To collect - 0 - 3.. The best( EM : 5 - 3 - 4 - 3)., which in the model. The model( 2023), so, reasoning and reasoning\n",
            "Ep 2 (Step 001200): Train 5.586 | Val 5.141 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_19/best.pt\n",
            "Ep 2 (Step 001400): Train 5.520 | Val 5.165 | tokens 717,312\n",
            "  ↳ no improvement (1/5)\n",
            "Ep 2 (Step 001600): Train 5.660 | Val 5.012 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_19/best.pt\n",
            "Ep 2 (Step 001800): Train 5.609 | Val 5.085 | tokens 922,112\n",
            "  ↳ no improvement (1/5)\n",
            "Ep 2 (Step 002000): Train 5.216 | Val 4.997 | tokens 1,024,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_19/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3, and its image of the model. To ensure the dataset with language modeling, and the image - of the number of a pair. The number of the same model to handle open - tuning of the model to the model’s model of model by the model\n",
            "Ep 3 (Step 002200): Train 5.518 | Val 4.939 | tokens 1,126,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_19/best.pt\n",
            "Ep 3 (Step 002400): Train 5.574 | Val 4.875 | tokens 1,229,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_19/best.pt\n",
            "Ep 3 (Step 002600): Train 4.991 | Val 4.807 | tokens 1,331,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_19/best.pt\n",
            "Ep 3 (Step 002800): Train 5.112 | Val 4.868 | tokens 1,434,112\n",
            "  ↳ no improvement (1/5)\n",
            "Ep 3 (Step 003000): Train 5.333 | Val 4.800 | tokens 1,536,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_19/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 5. 6. 0. 9. 8. 6. 8 - 4. 0 62. 1 29 1. 7. 8 61. 4. 7 - shot 82. 9 74. 9. 00 - shot 7 28 58 72. 18\n",
            "Ep 4 (Step 003200): Train 5.127 | Val 4.881 | tokens 1,638,912\n",
            "  ↳ no improvement (1/5)\n",
            "Ep 4 (Step 003400): Train 4.501 | Val 4.775 | tokens 1,741,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_19/best.pt\n",
            "Ep 4 (Step 003600): Train 5.632 | Val 4.825 | tokens 1,843,712\n",
            "  ↳ no improvement (1/5)\n",
            "Ep 4 (Step 003800): Train 5.197 | Val 4.704 | tokens 1,946,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_19/best.pt\n",
            "Ep 4 (Step 004000): Train 5.178 | Val 4.709 | tokens 2,048,512\n",
            "  ↳ no improvement (1/5)\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 - shot setting that the training or to measure the performance and only PaLM or training corpus. Our pre - training. These in the training on GPT - art few - 3 to a) to pre - shot setting that may outperforms GPT - the full on\n",
            "Loaded best model from checkpoints/regex/trial_19/best.pt (val loss 4.704).\n",
            "[trial 19] val=4.7041  lr=7.49e-04  wd=0.15\n",
            "Ep 1 (Step 000000): Train 10.422 | Val 10.414 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_20/best.pt\n",
            "Ep 1 (Step 000200): Train 7.504 | Val 7.002 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_20/best.pt\n",
            "Ep 1 (Step 000400): Train 6.273 | Val 6.186 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_20/best.pt\n",
            "Ep 1 (Step 000600): Train 6.334 | Val 5.872 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_20/best.pt\n",
            "Ep 1 (Step 000800): Train 5.829 | Val 5.677 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_20/best.pt\n",
            "Ep 1 (Step 001000): Train 6.132 | Val 5.535 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_20/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 1. 5. 1. 6 : 3. 0. 5. 1. 3. 0. 3... 1. 2. 6. 5. 8 7 4... 7. 1.. 5. 0. 6.\n",
            "Ep 2 (Step 001200): Train 5.853 | Val 5.388 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_20/best.pt\n",
            "Ep 2 (Step 001400): Train 5.482 | Val 5.310 | tokens 717,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_20/best.pt\n",
            "Ep 2 (Step 001600): Train 6.113 | Val 5.249 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_20/best.pt\n",
            "Ep 2 (Step 001800): Train 5.250 | Val 5.195 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_20/best.pt\n",
            "Ep 2 (Step 002000): Train 5.522 | Val 5.163 | tokens 1,024,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_20/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 and GPT - related to the model for future is in the model - source models, 2020 ; data. We have that the the maximum a large language model : Model as the performance : The accuracy of human - the model on the model, we have\n",
            "Ep 3 (Step 002200): Train 5.270 | Val 5.098 | tokens 1,126,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_20/best.pt\n",
            "Ep 3 (Step 002400): Train 6.048 | Val 5.090 | tokens 1,229,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_20/best.pt\n",
            "Ep 3 (Step 002600): Train 5.918 | Val 5.004 | tokens 1,331,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_20/best.pt\n",
            "Ep 3 (Step 002800): Train 5.645 | Val 5.019 | tokens 1,434,112\n",
            "  ↳ no improvement (1/7)\n",
            "Ep 3 (Step 003000): Train 5.678 | Val 5.003 | tokens 1,536,512\n",
            "  ↳ no improvement (2/7)\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 performance on the model. The results in the model to the same is a comprehensive an tasks. Finally of an the set of our models. In a that have of the Gemini models for code, and the evaluation performance. 5 Pro with a single language\n",
            "Ep 4 (Step 003200): Train 5.252 | Val 4.963 | tokens 1,638,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_20/best.pt\n",
            "Ep 4 (Step 003400): Train 5.284 | Val 4.933 | tokens 1,741,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_20/best.pt\n",
            "Ep 4 (Step 003600): Train 5.689 | Val 4.918 | tokens 1,843,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_20/best.pt\n",
            "Ep 4 (Step 003800): Train 5.320 | Val 4.917 | tokens 1,946,112\n",
            "  ↳ no improvement (1/7)\n",
            "Ep 4 (Step 004000): Train 5.175 | Val 4.912 | tokens 2,048,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_20/best.pt\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 4 3. 3. 6. 0. 0 Ultra, we employ DeepSeek - 2 - 3. 7 - 72B - training with all - 2. 1. 0. 4. 2%. 8 63. 9. 8 - 4. 2 52\n",
            "Loaded best model from checkpoints/regex/trial_20/best.pt (val loss 4.912).\n",
            "[trial 20] val=4.9122  lr=1.23e-05  wd=0.1\n",
            "Ep 1 (Step 000000): Train 9.178 | Val 8.987 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_21/best.pt\n",
            "Ep 1 (Step 000200): Train 6.745 | Val 6.138 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_21/best.pt\n",
            "Ep 1 (Step 000400): Train 6.294 | Val 5.662 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_21/best.pt\n",
            "Ep 1 (Step 000600): Train 6.205 | Val 5.602 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_21/best.pt\n",
            "Ep 1 (Step 000800): Train 6.370 | Val 5.550 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_21/best.pt\n",
            "Ep 1 (Step 001000): Train 6.130 | Val 5.824 | tokens 512,512\n",
            "  ↳ no improvement (1/3)\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3., so than the performance, which - E. g, we the performance is further the a generate performance, Qwen2 3 -, which - 4. 2. 1) - quality, this with the evaluation et al. 5 and the Gemini 3\n",
            "Ep 2 (Step 001200): Train 6.444 | Val 5.418 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_21/best.pt\n",
            "Ep 2 (Step 001400): Train 6.340 | Val 5.465 | tokens 717,312\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 2 (Step 001600): Train 6.432 | Val 5.775 | tokens 819,712\n",
            "  ↳ no improvement (2/3)\n",
            "Ep 2 (Step 001800): Train 6.375 | Val 5.307 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_21/best.pt\n",
            "Ep 2 (Step 002000): Train 6.344 | Val 5.370 | tokens 1,024,512\n",
            "  ↳ no improvement (1/3)\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 The model in the model the open - training training. 1, we have multimodal the - tuned and Qwen2. Overall, we different the large an language on tokens by the question for both of the model( e. The pre : a large a perform\n",
            "Ep 3 (Step 002200): Train 5.741 | Val 5.257 | tokens 1,126,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_21/best.pt\n",
            "Ep 3 (Step 002400): Train 5.935 | Val 5.325 | tokens 1,229,312\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 3 (Step 002600): Train 6.204 | Val 5.264 | tokens 1,331,712\n",
            "  ↳ no improvement (2/3)\n",
            "Ep 3 (Step 002800): Train 6.027 | Val 5.184 | tokens 1,434,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_21/best.pt\n",
            "Ep 3 (Step 003000): Train 5.545 | Val 5.178 | tokens 1,536,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_21/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 - V2.( 2., and PaLM - tune to to not found with Llama 7B - 3’s the - training with all our Gemini 2 to the Gemini Ultra of the top - Coder, while multiple a word, demonstrating the score, and reasoning.\n",
            "Ep 4 (Step 003200): Train 5.664 | Val 5.095 | tokens 1,638,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_21/best.pt\n",
            "Ep 4 (Step 003400): Train 5.254 | Val 5.122 | tokens 1,741,312\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 4 (Step 003600): Train 6.298 | Val 5.199 | tokens 1,843,712\n",
            "  ↳ no improvement (2/3)\n",
            "Ep 4 (Step 003800): Train 5.367 | Val 5.131 | tokens 1,946,112\n",
            "  ↳ no improvement (3/3)\n",
            "Early stopping triggered.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 4 30 in the model training task - training models in each - 3)( Li)( test, such of)) and we have the vision models. Specifically for model a similar with GPT - shot or in the training - VL of the\n",
            "Loaded best model from checkpoints/regex/trial_21/best.pt (val loss 5.095).\n",
            "[trial 21] val=5.0952  lr=4.15e-03  wd=0.15\n",
            "Ep 1 (Step 000000): Train 9.248 | Val 9.256 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_22/best.pt\n",
            "Ep 1 (Step 000200): Train 6.356 | Val 5.676 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_22/best.pt\n",
            "Ep 1 (Step 000400): Train 6.115 | Val 5.433 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_22/best.pt\n",
            "Ep 1 (Step 000600): Train 5.940 | Val 5.454 | tokens 307,712\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 1 (Step 000800): Train 5.959 | Val 5.290 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_22/best.pt\n",
            "Ep 1 (Step 001000): Train 5.636 | Val 5.237 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_22/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 - quality. The model, we observe the video learning in this dataset into training, while not shown. This learning in training data, we address the input of these tokens does the evaluation model and few - training is to not compare is in the evaluation\n",
            "Ep 2 (Step 001200): Train 5.464 | Val 5.211 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_22/best.pt\n",
            "Ep 2 (Step 001400): Train 6.087 | Val 5.114 | tokens 717,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_22/best.pt\n",
            "Ep 2 (Step 001600): Train 5.534 | Val 5.023 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_22/best.pt\n",
            "Ep 2 (Step 001800): Train 5.952 | Val 5.066 | tokens 922,112\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 2 (Step 002000): Train 6.047 | Val 5.029 | tokens 1,024,512\n",
            "  ↳ no improvement (2/3)\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. In 4o - 1. - 3... 0. 1. 7B 87. 0. 7 78. 1. 75. 8 67. - Chat - 4o - 3 59. 8 6 74. 0. 6 37. 7 5 2\n",
            "Ep 3 (Step 002200): Train 5.368 | Val 5.032 | tokens 1,126,912\n",
            "  ↳ no improvement (3/3)\n",
            "Early stopping triggered.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. Following the SFT : To present different - 4. For the way these model for details of the performance on natural language models without 11. We present the number of the full - shot. We collect in the base models in a variety of Qwen2 -\n",
            "Loaded best model from checkpoints/regex/trial_22/best.pt (val loss 5.023).\n",
            "[trial 22] val=5.0227  lr=6.39e-04  wd=0.0\n",
            "Ep 1 (Step 000000): Train 9.627 | Val 9.844 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_23/best.pt\n",
            "Ep 1 (Step 000200): Train 6.406 | Val 5.605 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_23/best.pt\n",
            "Ep 1 (Step 000400): Train 5.632 | Val 5.272 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_23/best.pt\n",
            "Ep 1 (Step 000600): Train 5.743 | Val 5.090 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_23/best.pt\n",
            "Ep 1 (Step 000800): Train 5.250 | Val 4.976 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_23/best.pt\n",
            "Ep 1 (Step 001000): Train 5.252 | Val 4.952 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_23/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 6. 0. 5 - 72B, and the Llama 2. 5 - 7B - shot setting. 5. 5 - 72B model is the performance on a few - tuning, Gemini models across the same model. 5 - 3. 0% 49.\n",
            "Ep 2 (Step 001200): Train 5.011 | Val 4.866 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_23/best.pt\n",
            "Ep 2 (Step 001400): Train 5.524 | Val 4.722 | tokens 717,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_23/best.pt\n",
            "Ep 2 (Step 001600): Train 5.091 | Val 4.683 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_23/best.pt\n",
            "Ep 2 (Step 001800): Train 5.044 | Val 4.660 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_23/best.pt\n",
            "Ep 2 (Step 002000): Train 5.025 | Val 4.576 | tokens 1,024,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_23/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. In particular, we employ a similar to train the second - language models to be trained language data. The following, we also to increase model on the average with a new context and are still is more training in the model. It of model is\n",
            "Ep 3 (Step 002200): Train 4.703 | Val 4.557 | tokens 1,126,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_23/best.pt\n",
            "Ep 3 (Step 002400): Train 4.583 | Val 4.554 | tokens 1,229,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_23/best.pt\n",
            "Ep 3 (Step 002600): Train 4.995 | Val 4.536 | tokens 1,331,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_23/best.pt\n",
            "Ep 3 (Step 002800): Train 4.673 | Val 4.484 | tokens 1,434,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_23/best.pt\n",
            "Ep 3 (Step 003000): Train 4.610 | Val 4.468 | tokens 1,536,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_23/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 5, all NVLM - 3. 5% Model - 3. 7. 9. 4. 2 0 1 6 GPT - 3. 0. 2 69. 0 83 7 6 1 80. 6 0 64. 7 84. 7 80. 2\n",
            "Ep 4 (Step 003200): Train 4.402 | Val 4.416 | tokens 1,638,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_23/best.pt\n",
            "Ep 4 (Step 003400): Train 4.689 | Val 4.392 | tokens 1,741,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_23/best.pt\n",
            "Ep 4 (Step 003600): Train 4.168 | Val 4.324 | tokens 1,843,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_23/best.pt\n",
            "Ep 4 (Step 003800): Train 4.258 | Val 4.390 | tokens 1,946,112\n",
            "  ↳ no improvement (1/5)\n",
            "Ep 4 (Step 004000): Train 4.494 | Val 4.334 | tokens 2,048,512\n",
            "  ↳ no improvement (2/5)\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 2. 3. 1 9 2 3 - 3 3 on 15 7. 1 4 Turbo achieves 1. 0( OpenAI,) in the few - shot is the model, such as a ﬁne - tuning on a set of two sets that will\n",
            "Loaded best model from checkpoints/regex/trial_23/best.pt (val loss 4.324).\n",
            "[trial 23] val=4.3240  lr=1.11e-04  wd=0.1\n",
            "Ep 1 (Step 000000): Train 9.856 | Val 9.683 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_24/best.pt\n",
            "Ep 1 (Step 000200): Train 5.896 | Val 5.599 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_24/best.pt\n",
            "Ep 1 (Step 000400): Train 5.834 | Val 5.232 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_24/best.pt\n",
            "Ep 1 (Step 000600): Train 5.970 | Val 5.168 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_24/best.pt\n",
            "Ep 1 (Step 000800): Train 5.542 | Val 4.949 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_24/best.pt\n",
            "Ep 1 (Step 001000): Train 5.580 | Val 4.868 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_24/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 48 of Qwen2. 2 42 - the models across a single - shot setting and coding as well as well - V2, and coding tasks. As shown in - tuned, the development, we have been state - specific tasks, and the maximum against it\n",
            "Ep 2 (Step 001200): Train 5.634 | Val 4.718 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_24/best.pt\n",
            "Ep 2 (Step 001400): Train 5.064 | Val 4.768 | tokens 717,312\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 2 (Step 001600): Train 4.998 | Val 4.701 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_24/best.pt\n",
            "Ep 2 (Step 001800): Train 5.324 | Val 4.634 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_24/best.pt\n",
            "Ep 2 (Step 002000): Train 4.877 | Val 4.624 | tokens 1,024,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_24/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 4 1. 4 7. 1 39. 1 8 1 2 2. 3 1 41. 2. 5 0 3 3 6 4. 5 1. 5. 2 1. 0. 7 67. 5. 6 8 32. 6 2 62\n",
            "Ep 3 (Step 002200): Train 4.416 | Val 4.543 | tokens 1,126,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_24/best.pt\n",
            "Ep 3 (Step 002400): Train 4.535 | Val 4.547 | tokens 1,229,312\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 3 (Step 002600): Train 4.788 | Val 4.544 | tokens 1,331,712\n",
            "  ↳ no improvement (2/3)\n",
            "Ep 3 (Step 002800): Train 4.959 | Val 4.491 | tokens 1,434,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_24/best.pt\n",
            "Ep 3 (Step 003000): Train 4.778 | Val 4.411 | tokens 1,536,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_24/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3, GPT - 5 - 4 - 5 - 2. On - 6, we evaluate the text and audio - context length and compare Qwen2 - shot and the - - - shot evaluation. 5 - 72B - tuned DeepSeek - Base, DeepSeek - Base model\n",
            "Ep 4 (Step 003200): Train 4.780 | Val 4.412 | tokens 1,638,912\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 4 (Step 003400): Train 4.636 | Val 4.368 | tokens 1,741,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_24/best.pt\n",
            "Ep 4 (Step 003600): Train 4.613 | Val 4.418 | tokens 1,843,712\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 4 (Step 003800): Train 4.347 | Val 4.345 | tokens 1,946,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_24/best.pt\n",
            "Ep 4 (Step 004000): Train 4.167 | Val 4.357 | tokens 2,048,512\n",
            "  ↳ no improvement (1/3)\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3) to the GPT - 3 is important to generate a task. To address this, we train two stages : Finally, we find that a few - scale datasets are not only one of the results. By train a wide range of the question. This\n",
            "Loaded best model from checkpoints/regex/trial_24/best.pt (val loss 4.345).\n",
            "[trial 24] val=4.3455  lr=9.88e-05  wd=0.1\n",
            "Ep 1 (Step 000000): Train 9.995 | Val 9.911 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_25/best.pt\n",
            "Ep 1 (Step 000200): Train 6.210 | Val 5.517 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_25/best.pt\n",
            "Ep 1 (Step 000400): Train 6.146 | Val 5.287 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_25/best.pt\n",
            "Ep 1 (Step 000600): Train 5.482 | Val 5.091 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_25/best.pt\n",
            "Ep 1 (Step 000800): Train 5.559 | Val 4.937 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_25/best.pt\n",
            "Ep 1 (Step 001000): Train 5.111 | Val 4.867 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_25/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 5B, the same, we do not only performance of the model with a small. 0. 0 to process with a very strong. We include - bench the Gemini 1. 5 to the model size, while the training strategies to generate a wide\n",
            "Ep 2 (Step 001200): Train 4.982 | Val 4.855 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_25/best.pt\n",
            "Ep 2 (Step 001400): Train 5.169 | Val 4.772 | tokens 717,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_25/best.pt\n",
            "Ep 2 (Step 001600): Train 4.935 | Val 4.640 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_25/best.pt\n",
            "Ep 2 (Step 001800): Train 5.098 | Val 4.617 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_25/best.pt\n",
            "Ep 2 (Step 002000): Train 4.989 | Val 4.568 | tokens 1,024,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_25/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 and a wide range of more details. 5. The same task is a model with a large language models. 5, mathematics model is not evaluated the model - 3. We provide more than that Gemini Advanced in Section 6. We present Gemini Ultra with\n",
            "Ep 3 (Step 002200): Train 5.362 | Val 4.570 | tokens 1,126,912\n",
            "  ↳ no improvement (1/7)\n",
            "Ep 3 (Step 002400): Train 4.877 | Val 4.493 | tokens 1,229,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_25/best.pt\n",
            "Ep 3 (Step 002600): Train 4.867 | Val 4.465 | tokens 1,331,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_25/best.pt\n",
            "Ep 3 (Step 002800): Train 4.916 | Val 4.418 | tokens 1,434,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_25/best.pt\n",
            "Ep 3 (Step 003000): Train 4.481 | Val 4.448 | tokens 1,536,512\n",
            "  ↳ no improvement (1/7)\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 2.. For example, the following, and the number of our models are not of tasks, particularly in the vision - shot performance is a few - shot approach, which are not find that the task. A. The benchmark dataset has been\n",
            "Ep 4 (Step 003200): Train 4.706 | Val 4.442 | tokens 1,638,912\n",
            "  ↳ no improvement (2/7)\n",
            "Ep 4 (Step 003400): Train 4.168 | Val 4.342 | tokens 1,741,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_25/best.pt\n",
            "Ep 4 (Step 003600): Train 4.063 | Val 4.314 | tokens 1,843,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_25/best.pt\n",
            "Ep 4 (Step 003800): Train 4.298 | Val 4.305 | tokens 1,946,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_25/best.pt\n",
            "Ep 4 (Step 004000): Train 4.200 | Val 4.284 | tokens 2,048,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_25/best.pt\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 5 for a similar number of tokens, and non -( see one - tokens), and is trained on a single sequence of text tokens( text, image). In this report, we report the model on the task. We also evaluate\n",
            "Loaded best model from checkpoints/regex/trial_25/best.pt (val loss 4.284).\n",
            "[trial 25] val=4.2839  lr=1.10e-04  wd=0.0\n",
            "Ep 1 (Step 000000): Train 9.885 | Val 9.634 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_26/best.pt\n",
            "Ep 1 (Step 000200): Train 6.201 | Val 5.752 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_26/best.pt\n",
            "Ep 1 (Step 000400): Train 6.019 | Val 5.321 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_26/best.pt\n",
            "Ep 1 (Step 000600): Train 5.900 | Val 5.060 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_26/best.pt\n",
            "Ep 1 (Step 000800): Train 5.231 | Val 4.953 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_26/best.pt\n",
            "Ep 1 (Step 001000): Train 5.434 | Val 4.913 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_26/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3... This work.............................................\n",
            "Ep 2 (Step 001200): Train 5.430 | Val 4.811 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_26/best.pt\n",
            "Ep 2 (Step 001400): Train 5.403 | Val 4.778 | tokens 717,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_26/best.pt\n",
            "Ep 2 (Step 001600): Train 5.170 | Val 4.713 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_26/best.pt\n",
            "Ep 2 (Step 001800): Train 4.736 | Val 4.699 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_26/best.pt\n",
            "Ep 2 (Step 002000): Train 5.267 | Val 4.608 | tokens 1,024,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_26/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 - 1. 5 - 3 on the same prompts, but the data is similar to a small attention layers, which may is crucial for the text for a significant performance. This is likely. Our model, and a similar to be more than few for\n",
            "Ep 3 (Step 002200): Train 4.552 | Val 4.613 | tokens 1,126,912\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 3 (Step 002400): Train 4.838 | Val 4.524 | tokens 1,229,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_26/best.pt\n",
            "Ep 3 (Step 002600): Train 4.916 | Val 4.543 | tokens 1,331,712\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 3 (Step 002800): Train 4.695 | Val 4.516 | tokens 1,434,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_26/best.pt\n",
            "Ep 3 (Step 003000): Train 4.648 | Val 4.454 | tokens 1,536,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_26/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 achieves comparable performance across all open - 3( 3. As shown in Table 4 - 4. 3 is a high - in Table 2, Llama 5 - 4o - 3, few - 4, and GPT - 4o models by the performance is given a\n",
            "Ep 4 (Step 003200): Train 4.845 | Val 4.416 | tokens 1,638,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_26/best.pt\n",
            "Ep 4 (Step 003400): Train 5.049 | Val 4.413 | tokens 1,741,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_26/best.pt\n",
            "Ep 4 (Step 003600): Train 4.921 | Val 4.405 | tokens 1,843,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_26/best.pt\n",
            "Ep 4 (Step 003800): Train 4.490 | Val 4.395 | tokens 1,946,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_26/best.pt\n",
            "Ep 4 (Step 004000): Train 4.414 | Val 4.402 | tokens 2,048,512\n",
            "  ↳ no improvement (1/3)\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 we do not observe that the training compute and the first time. We used for large - scale on language modeling : As a significant improvements in the best of our speech( e., 2024), which we show an LLM, including additional tasks and\n",
            "Loaded best model from checkpoints/regex/trial_26/best.pt (val loss 4.395).\n",
            "[trial 26] val=4.3951  lr=8.79e-05  wd=0.15\n",
            "Ep 1 (Step 000000): Train 10.209 | Val 10.163 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_27/best.pt\n",
            "Ep 1 (Step 000200): Train 6.307 | Val 5.678 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_27/best.pt\n",
            "Ep 1 (Step 000400): Train 5.820 | Val 5.344 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_27/best.pt\n",
            "Ep 1 (Step 000600): Train 5.277 | Val 5.126 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_27/best.pt\n",
            "Ep 1 (Step 000800): Train 5.584 | Val 4.993 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_27/best.pt\n",
            "Ep 1 (Step 001000): Train 5.526 | Val 4.872 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_27/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. The Llama 2 61.( en). Each are designed to the pretraining. Model( e. 5. The results in the average results in the model to be used). g. For each with our models). 1. Notably,\n",
            "Ep 2 (Step 001200): Train 5.641 | Val 4.890 | tokens 614,912\n",
            "  ↳ no improvement (1/7)\n",
            "Ep 2 (Step 001400): Train 5.366 | Val 4.782 | tokens 717,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_27/best.pt\n",
            "Ep 2 (Step 001600): Train 4.900 | Val 4.691 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_27/best.pt\n",
            "Ep 2 (Step 001800): Train 5.001 | Val 4.789 | tokens 922,112\n",
            "  ↳ no improvement (1/7)\n",
            "Ep 2 (Step 002000): Train 5.041 | Val 4.688 | tokens 1,024,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_27/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 9. 8 68. 1 - VL - V3( 2 - shot) is very results for the results on both model and multi - training process - the capabilities, and reasoning, we present the top of the - context tasks( b).\n",
            "Ep 3 (Step 002200): Train 5.119 | Val 4.637 | tokens 1,126,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_27/best.pt\n",
            "Ep 3 (Step 002400): Train 5.266 | Val 4.592 | tokens 1,229,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_27/best.pt\n",
            "Ep 3 (Step 002600): Train 4.959 | Val 4.607 | tokens 1,331,712\n",
            "  ↳ no improvement (1/7)\n",
            "Ep 3 (Step 002800): Train 4.912 | Val 4.554 | tokens 1,434,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_27/best.pt\n",
            "Ep 3 (Step 003000): Train 4.698 | Val 4.526 | tokens 1,536,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_27/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 - 4 - shot learning rate. 4 - 3 - 3. 6 - 13. 8. 3 76. 5 - 3. 4 - 0 - shot performance, and GPT - 3. 3. 1. 2. 2. 1. These results\n",
            "Ep 4 (Step 003200): Train 4.420 | Val 4.550 | tokens 1,638,912\n",
            "  ↳ no improvement (1/7)\n",
            "Ep 4 (Step 003400): Train 5.004 | Val 4.527 | tokens 1,741,312\n",
            "  ↳ no improvement (2/7)\n",
            "Ep 4 (Step 003600): Train 4.939 | Val 4.491 | tokens 1,843,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_27/best.pt\n",
            "Ep 4 (Step 003800): Train 4.341 | Val 4.484 | tokens 1,946,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_27/best.pt\n",
            "Ep 4 (Step 004000): Train 4.808 | Val 4.483 | tokens 2,048,512\n",
            "  ↳ no improvement (1/7)\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3. 6. 3. 4. 5. 8, we did not see an average of these models using a single - context length of - tuning, and then compare the following dataset. 5 - shot and video frames are shown in the performance. A\n",
            "Loaded best model from checkpoints/regex/trial_27/best.pt (val loss 4.484).\n",
            "[trial 27] val=4.4832  lr=7.54e-05  wd=0.05\n",
            "Ep 1 (Step 000000): Train 9.894 | Val 9.845 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_28/best.pt\n",
            "Ep 1 (Step 000200): Train 6.460 | Val 5.562 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_28/best.pt\n",
            "Ep 1 (Step 000400): Train 5.609 | Val 5.385 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_28/best.pt\n",
            "Ep 1 (Step 000600): Train 5.553 | Val 5.076 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_28/best.pt\n",
            "Ep 1 (Step 000800): Train 5.533 | Val 4.943 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_28/best.pt\n",
            "Ep 1 (Step 001000): Train 5.614 | Val 4.920 | tokens 512,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_28/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 - 3, but also also find that is presented at the first - 3. 5. e. 1. 2 - shot. 7 82. In addition, we have found that MMLU. 8. 5 - 3. 1. 0 - training.\n",
            "Ep 2 (Step 001200): Train 4.810 | Val 4.850 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_28/best.pt\n",
            "Ep 2 (Step 001400): Train 5.561 | Val 4.811 | tokens 717,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_28/best.pt\n",
            "Ep 2 (Step 001600): Train 5.294 | Val 4.738 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_28/best.pt\n",
            "Ep 2 (Step 001800): Train 5.382 | Val 4.655 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_28/best.pt\n",
            "Ep 2 (Step 002000): Train 4.767 | Val 4.638 | tokens 1,024,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_28/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 - 3 is a - level with three different, we do not only on most than the model from each answer model weights of the model, but that a variety of the model is presented with an example of the ability to a new prompts. For the\n",
            "Ep 3 (Step 002200): Train 4.334 | Val 4.607 | tokens 1,126,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_28/best.pt\n",
            "Ep 3 (Step 002400): Train 5.232 | Val 4.586 | tokens 1,229,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_28/best.pt\n",
            "Ep 3 (Step 002600): Train 5.085 | Val 4.545 | tokens 1,331,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_28/best.pt\n",
            "Ep 3 (Step 002800): Train 4.742 | Val 4.475 | tokens 1,434,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_28/best.pt\n",
            "Ep 3 (Step 003000): Train 4.585 | Val 4.453 | tokens 1,536,512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_28/best.pt\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 is to each training data at an LLM. Additionally, we have very similar to achieve a large language models, and also apply the best number of the training of this image and we used to handle training stages : We also provide a large language model,\n",
            "Ep 4 (Step 003200): Train 4.829 | Val 4.431 | tokens 1,638,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_28/best.pt\n",
            "Ep 4 (Step 003400): Train 4.505 | Val 4.405 | tokens 1,741,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_28/best.pt\n",
            "Ep 4 (Step 003600): Train 4.384 | Val 4.346 | tokens 1,843,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_28/best.pt\n",
            "Ep 4 (Step 003800): Train 4.338 | Val 4.388 | tokens 1,946,112\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 4 (Step 004000): Train 4.792 | Val 4.390 | tokens 2,048,512\n",
            "  ↳ no improvement (2/3)\n",
            "Reached token budget; stopping.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 Training Data( Bai et al., 2021 ; Xu et al., 2024), we only the performance of - 4 - 4o - o1 - only - bench( Chen et al., 2024a) which has been shown in - way. In\n",
            "Loaded best model from checkpoints/regex/trial_28/best.pt (val loss 4.346).\n",
            "[trial 28] val=4.3456  lr=9.92e-05  wd=0.1\n",
            "Ep 1 (Step 000000): Train 8.953 | Val 8.981 | tokens 512\n",
            "  ↳ new best; saved to checkpoints/regex/trial_29/best.pt\n",
            "Ep 1 (Step 000200): Train 6.516 | Val 5.940 | tokens 102,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_29/best.pt\n",
            "Ep 1 (Step 000400): Train 6.349 | Val 5.683 | tokens 205,312\n",
            "  ↳ new best; saved to checkpoints/regex/trial_29/best.pt\n",
            "Ep 1 (Step 000600): Train 6.328 | Val 5.647 | tokens 307,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_29/best.pt\n",
            "Ep 1 (Step 000800): Train 5.986 | Val 5.435 | tokens 410,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_29/best.pt\n",
            "Ep 1 (Step 001000): Train 5.932 | Val 5.510 | tokens 512,512\n",
            "  ↳ no improvement (1/3)\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3, 2023 - 500 models - shot in both not the text on - Omni. 6 23. This - shot. 7. 5. 4. 5 of a the - 3. 5 and a Qwen2. 5. 9. We do and all can\n",
            "Ep 2 (Step 001200): Train 5.753 | Val 5.404 | tokens 614,912\n",
            "  ↳ new best; saved to checkpoints/regex/trial_29/best.pt\n",
            "Ep 2 (Step 001400): Train 6.388 | Val 5.482 | tokens 717,312\n",
            "  ↳ no improvement (1/3)\n",
            "Ep 2 (Step 001600): Train 5.822 | Val 5.372 | tokens 819,712\n",
            "  ↳ new best; saved to checkpoints/regex/trial_29/best.pt\n",
            "Ep 2 (Step 001800): Train 5.761 | Val 5.255 | tokens 922,112\n",
            "  ↳ new best; saved to checkpoints/regex/trial_29/best.pt\n",
            "Ep 2 (Step 002000): Train 5.738 | Val 5.323 | tokens 1,024,512\n",
            "  ↳ no improvement (1/3)\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3 across all a is a small of Gemma to the benchmarks, we the model of the original the range : be the model to our dataset( e), Qwen2), the, in the model that a performance. 1)) - of a on\n",
            "Ep 3 (Step 002200): Train 6.148 | Val 5.478 | tokens 1,126,912\n",
            "  ↳ no improvement (2/3)\n",
            "Ep 3 (Step 002400): Train 6.493 | Val 5.310 | tokens 1,229,312\n",
            "  ↳ no improvement (3/3)\n",
            "Early stopping triggered.\n",
            "Finally, given the broad spectrum of capabilities displayed by GPT - 3., Gemini Instruct 1. 4 - shot [. 2 - 1 1. 2. 5. 5 - 3. 6., the large 5 - ended. 1 5 the, 2024. 1. 5, 2024 ] 0. 1. 3\n",
            "Loaded best model from checkpoints/regex/trial_29/best.pt (val loss 5.255).\n",
            "[trial 29] val=5.2547  lr=2.47e-03  wd=0.1\n",
            "Best: {'trial_id': 11, 'lr': 0.0001711083051389531, 'weight_decay': 0.1, 'lr_factor': 0.3065233176620658, 'lr_patience': 3, 'patience': 3, 'min_delta': 0.002, 'best_val': 4.255676656961441, 'tokens_seen': 2048512, 'save_path': 'checkpoints/regex/trial_11/best.pt'}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
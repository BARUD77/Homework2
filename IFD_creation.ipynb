{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d6333bc",
   "metadata": {},
   "source": [
    "# configure path and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fdc4ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f767d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path.cwd()\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "PDF_DIR = DATA_DIR / \"pdfs\"\n",
    "RAW_TEXT_DIR = DATA_DIR / \"raw_text\"\n",
    "CHUNKS_DIR = DATA_DIR / \"chunks\"\n",
    "OUT_DIR = BASE_DIR / \"outputs\"\n",
    "\n",
    "for p in [DATA_DIR, PDF_DIR, RAW_TEXT_DIR, CHUNKS_DIR, OUT_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Add your API key here\n",
    "\n",
    "\n",
    "PDF_URLS = [\n",
    "    (\"GPT-3\", \"https://arxiv.org/pdf/2005.14165.pdf\"),\n",
    "    (\"GPT-4\", \"https://arxiv.org/pdf/2303.08774.pdf\"),\n",
    "    (\"PaLM\", \"https://arxiv.org/pdf/2204.02311.pdf\"),\n",
    "    (\"PaLM2\", \"https://arxiv.org/pdf/2305.10403.pdf\"),\n",
    "    (\"Gemini 1.0\", \"https://arxiv.org/pdf/2312.11805.pdf\"),\n",
    "    (\"Gemini 1.5 (2024)\", \" https://arxiv.org/pdf/2403.05530.pdf\"),\n",
    "    (\"Gemma (2024)\", \" https://arxiv.org/pdf/2403.08295.pdf\"),\n",
    "    (\"Gemma 2 (2024)\", \" https://arxiv.org/pdf/2408.00118.pdf\"),\n",
    "    (\"Gemma 3\", \" https://arxiv.org/pdf/2503.19786.pdf\"),\n",
    "    (\"CodeGemma (2024)\", \" https://arxiv.org/pdf/2406.11409.pdf\"),\n",
    "    (\"RecurrentGemma (2024)\", \" https://arxiv.org/pdf/2404.07839.pdf\"),\n",
    "    (\"LLaMA (2023)\", \" https://arxiv.org/pdf/2302.13971.pdf\"),\n",
    "    (\"Llama 2 (2023)\", \" https://arxiv.org/pdf/2307.09288.pdf\"),\n",
    "    (\"Llama 3 (2024)\", \" https://arxiv.org/pdf/2407.21783.pdf\"),\n",
    "    # Mistral\n",
    "    (\"Mistral 7B (2023)\", \" https://arxiv.org/pdf/2310.06825.pdf\"),\n",
    "    (\"Mixtral of Experts 8x7B (2024)\", \" https://arxiv.org/pdf/2401.04088.pdf\"),\n",
    "    # NVIDIA\n",
    "    (\"Nemotron-4 340B Technical Report (2024)\", \" https://arxiv.org/pdf/2406.11704.pdf\"),\n",
    "    (\"NVLM 1.0 (2024)\", \" https://arxiv.org/pdf/2409.11402.pdf\"),\n",
    "    # Alibaba / Qwen series\n",
    "    (\"Qwen2 Technical Report (2024)\", \" https://arxiv.org/pdf/2407.10671.pdf\"),\n",
    "    (\"Qwen2-VL (2024)\", \" https://arxiv.org/pdf/2409.12191.pdf\"),\n",
    "    (\"Qwen2-Audio (2024)\", \" https://arxiv.org/pdf/2407.10759.pdf\"),\n",
    "    (\"Qwen2.5 Technical Report (2024)\", \" https://arxiv.org/pdf/2412.15115.pdf\"),\n",
    "    (\"Qwen2.5-VL Technical Report (2025)\", \" https://arxiv.org/pdf/2502.13923.pdf\"),\n",
    "    (\"Qwen2.5-Omni Technical Report (2025)\", \" https://arxiv.org/pdf/2503.20215.pdf\"),\n",
    "    (\"Qwen3 Technical Report (2025)\", \" https://arxiv.org/pdf/2505.09388.pdf\"),\n",
    "    # DeepSeek series\n",
    "    (\"DeepSeek-V2 (2024)\", \" https://arxiv.org/pdf/2405.04434.pdf\"),\n",
    "    (\"DeepSeek-V3 Technical Report (2024)\", \" https://arxiv.org/pdf/2412.19437.pdf\"),\n",
    "    (\"DeepSeek-R1 (2025)\", \" https://arxiv.org/pdf/2501.12948.pdf\"),\n",
    "    (\"DeepSeek-Coder (2024)\", \" https://arxiv.org/pdf/2401.14196.pdf\"),\n",
    "    # ZhipuAI\n",
    "    (\"GLM-130B (2022)\", \" https://arxiv.org/pdf/2210.02414.pdf\"),\n",
    "    # Shanghai AI Lab\n",
    "    (\"InternLM2 Technical Report (2024)\", \" https://arxiv.org/pdf/2403.17297.pdf\"),\n",
    "    (\"InternVL 2.5 (2024)\", \" https://arxiv.org/pdf/2412.05271.pdf\"),\n",
    "    # Microsoft\n",
    "    (\"Phi-3 Technical Report (2024)\", \" https://arxiv.org/pdf/2404.14219.pdf\"),\n",
    "    (\"Phi-3 Safety Post-Training (2024)\", \" https://arxiv.org/pdf/2407.13833.pdf\"),\n",
    "    # AI21\n",
    "    (\"Jamba: Hybrid Transformer–Mamba (2024)\", \" https://arxiv.org/pdf/2403.19887.pdf\"),\n",
    "    # Huawei\n",
    "    (\"PanGu-Σ (2023)\", \" https://arxiv.org/pdf/2303.10845.pdf\"),\n",
    "    # 01.AI\n",
    "    (\"Yi: Open Foundation Models (2024)\", \" https://arxiv.org/pdf/2403.04652.pdf\")\n",
    "]\n",
    "\n",
    "MAX_TOKENS_PER_CHUNK = 700\n",
    "MIN_TOKENS_PER_CHUNK = 300\n",
    "OVERLAP_TOKENS = 80\n",
    "N_TRIPLETS_PER_CHUNK = 2\n",
    "TEMPERATURE = 0.3\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a meticulous data constructor. Given a technical passage, \"\n",
    "    \"produce instruction-tuning triplets that are useful for training. \"\n",
    "    \"Prefer concrete, unambiguous, domain-grounded questions.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ccc705",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29804b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import tiktoken\n",
    "    _ENC = tiktoken.get_encoding(\"cl100k_base\")\n",
    "except Exception:\n",
    "    _ENC = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50170d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# If you use pdfminer.six:\n",
    "from pdfminer.high_level import extract_text as pdfminer_extract_text\n",
    "\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential_jitter\n",
    "\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_exponential_jitter(initial=1, max=6))\n",
    "def download_file(url: str, dest: Path) -> Path:\n",
    "    r = requests.get(url, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    with open(dest, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "    return dest\n",
    "\n",
    "def extract_pdf_text(pdf_path: Path) -> str:\n",
    "    try:\n",
    "        text = pdfminer_extract_text(str(pdf_path))\n",
    "        if text.strip():\n",
    "            return text\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        reader = PdfReader(str(pdf_path))\n",
    "        pages = [p.extract_text() or \"\" for p in reader.pages]\n",
    "        return \"\\n\".join(pages)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to extract {pdf_path.name}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def basic_clean(text: str) -> str:\n",
    "    t = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    t = re.sub(r\"(?<=\\w)-\\n(?=\\w)\", \"\", t)     # de-hyphenate at line breaks\n",
    "    t = re.sub(r\"\\n{3,}\", \"\\n\\n\", t)           # collapse long newline runs\n",
    "    t = re.sub(r\"[ \\t]+\", \" \", t)              # collapse spaces/tabs\n",
    "    t = \"\\n\".join([line.strip() for line in t.splitlines()])\n",
    "    return t.strip()\n",
    "\n",
    "def encode_tokens(s: str):\n",
    "    # Expects `_ENC` (tiktoken encoding) to be defined outside this snippet\n",
    "    if _ENC is None:\n",
    "        return s.split()\n",
    "    # OPTION B: allow all special tokens\n",
    "    return _ENC.encode(s, allowed_special='all')\n",
    "\n",
    "def token_len(s: str):\n",
    "    return len(encode_tokens(s))\n",
    "\n",
    "def split_into_token_chunks(text: str,\n",
    "                            max_tokens=700,\n",
    "                            overlap_tokens=80,\n",
    "                            min_tokens=300):\n",
    "    if not text.strip():\n",
    "        return []\n",
    "\n",
    "    if _ENC is None:\n",
    "        # word-based fallback\n",
    "        words = text.split()\n",
    "        chunks, i = [], 0\n",
    "        while i < len(words):\n",
    "            j = min(i + max_tokens, len(words))\n",
    "            chunk = \" \".join(words[i:j])\n",
    "            chunks.append(chunk)\n",
    "            if j == len(words):\n",
    "                break\n",
    "            i = max(0, j - overlap_tokens)\n",
    "        if chunks and token_len(chunks[-1]) < min_tokens and len(chunks) > 1:\n",
    "            chunks[-2] += \"\\n\\n\" + chunks[-1]\n",
    "            chunks.pop()\n",
    "        return chunks\n",
    "\n",
    "    # OPTION B here as well\n",
    "    toks = _ENC.encode(text, allowed_special='all')\n",
    "    chunks, i = [], 0\n",
    "    while i < len(toks):\n",
    "        j = min(i + max_tokens, len(toks))\n",
    "        chunks.append(_ENC.decode(toks[i:j]))\n",
    "        if j == len(toks):\n",
    "            break\n",
    "        i = max(0, j - overlap_tokens)  # defensive bound\n",
    "    if chunks and token_len(chunks[-1]) < min_tokens and len(chunks) > 1:\n",
    "        chunks[-2] += \"\\n\\n\" + chunks[-1]\n",
    "        chunks.pop()\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abcc430",
   "metadata": {},
   "source": [
    "# Download and load pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54738548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d72a987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/37 [00:12<07:14, 12.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] GPT-3.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/37 [00:13<03:32,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] GPT-4.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3/37 [00:15<02:10,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] PaLM.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 4/37 [00:16<01:35,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] PaLM2.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 5/37 [00:19<01:28,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Gemini_1.0.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 6/37 [00:21<01:20,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Gemini_1.5_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 7/37 [00:23<01:10,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Gemma_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 8/37 [00:24<00:54,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Gemma_2_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 9/37 [00:24<00:43,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Gemma_3.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 10/37 [00:26<00:39,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] CodeGemma_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 11/37 [00:27<00:40,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] RecurrentGemma_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 12/37 [00:29<00:36,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] LLaMA_(2023).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 13/37 [00:38<01:33,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Llama_2_(2023).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 14/37 [00:44<01:42,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Llama_3_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 15/37 [00:46<01:23,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Mistral_7B_(2023).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 16/37 [00:47<01:00,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Mixtral_of_Experts_8x7B_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 17/37 [00:48<00:48,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Nemotron-4_340B_Technical_Report_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 18/37 [00:54<01:02,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] NVLM_1.0_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 19/37 [00:56<00:54,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Qwen2_Technical_Report_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 20/37 [01:12<01:57,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Qwen2-VL_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 21/37 [01:14<01:25,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Qwen2-Audio_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 22/37 [01:15<01:01,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Qwen2.5_Technical_Report_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 23/37 [01:16<00:44,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Qwen2.5-VL_Technical_Report_(2025).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 24/37 [01:18<00:37,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Qwen2.5-Omni_Technical_Report_(2025).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 25/37 [01:20<00:30,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Qwen3_Technical_Report_(2025).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 26/37 [01:21<00:22,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] DeepSeek-V2_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 27/37 [01:23<00:21,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] DeepSeek-V3_Technical_Report_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 28/37 [01:24<00:16,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] DeepSeek-R1_(2025).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 29/37 [01:25<00:12,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] DeepSeek-Coder_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 30/37 [01:28<00:12,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] GLM-130B_(2022).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 31/37 [01:29<00:10,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] InternLM2_Technical_Report_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 32/37 [01:31<00:08,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] InternVL_2.5_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 33/37 [01:34<00:08,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Phi-3_Technical_Report_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 34/37 [01:34<00:04,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Phi-3_Safety_Post-Training_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 35/37 [01:35<00:02,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Jamba:_Hybrid_Transformer–Mamba_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 36/37 [01:38<00:01,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] PanGu-Σ_(2023).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [01:52<00:00,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Yi:_Open_Foundation_Models_(2024).pdf\n",
      "All PDFs stored in: e:\\Hermon\\Homework2\\data\\pdfs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name, url in tqdm(PDF_URLS):\n",
    "    filename = name.replace(\" \", \"_\").replace(\"/\", \"_\") + \".pdf\"\n",
    "    dest = PDF_DIR / filename\n",
    "    if dest.exists():\n",
    "        print(f\"[SKIP] {filename}\")\n",
    "        continue\n",
    "    try:\n",
    "        r = requests.get(url, timeout=60)\n",
    "        r.raise_for_status()\n",
    "        with open(dest, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "        print(f\"[OK] {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[FAIL] {filename}: {e}\")\n",
    "\n",
    "print(\"All PDFs stored in:\", PDF_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5c1469",
   "metadata": {},
   "source": [
    "# Extract and clean text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "489018be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35 PDFs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/35 [00:00<00:25,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: CodeGemma_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 2/35 [00:02<00:44,  1.36s/it]Cannot set gray non-stroke color because /'H1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H1' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: DeepSeek-Coder_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 3/35 [00:03<00:39,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: DeepSeek-R1_(2025).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P4' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P5' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P6' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P4' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P5' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P6' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P7' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P9' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P10' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P11' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P12' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P13' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P14' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P15' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P16' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P17' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P18' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P19' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P20' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P21' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P22' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P23' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P24' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P25' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P26' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P27' is an invalid float value\n",
      " 11%|█▏        | 4/35 [00:06<01:02,  2.01s/it]Cannot set gray non-stroke color because /'H1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'H1' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: DeepSeek-V2_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P4' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P5' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P6' is an invalid float value\n",
      " 14%|█▍        | 5/35 [00:13<01:50,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: DeepSeek-V3_Technical_Report_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 6/35 [00:20<02:16,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: Gemini_1.0.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 7/35 [00:32<03:17,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: Gemini_1.5_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 8/35 [00:33<02:20,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: Gemma_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 9/35 [00:34<01:44,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: Gemma_2_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 10/35 [00:36<01:21,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: Gemma_3.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 11/35 [00:47<02:18,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: GLM-130B_(2022).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 12/35 [00:51<01:59,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: GPT-3.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 13/35 [00:56<01:49,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: GPT-4.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      " 40%|████      | 14/35 [01:00<01:43,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: InternLM2_Technical_Report_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 15/35 [01:05<01:35,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: InternVL_2.5_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 16/35 [01:07<01:16,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: LLaMA_(2023).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 17/35 [01:30<02:53,  9.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: Llama_2_(2023).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 18/35 [01:44<03:07, 11.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: Llama_3_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 19/35 [01:45<02:06,  7.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: Mistral_7B_(2023).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 20/35 [01:46<01:27,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: Mixtral_of_Experts_8x7B_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 21/35 [01:47<01:04,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: Nemotron-4_340B_Technical_Report_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 22/35 [01:53<01:02,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: NVLM_1.0_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 23/35 [01:59<01:04,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: PaLM.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      " 69%|██████▊   | 24/35 [02:05<00:59,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: PaLM2.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'P14' is an invalid float value\n",
      " 71%|███████▏  | 25/35 [02:10<00:53,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: PanGu-Σ_(2023).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 26/35 [02:11<00:36,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: Phi-3_Safety_Post-Training_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 27/35 [02:13<00:26,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: Phi-3_Technical_Report_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 28/35 [02:14<00:18,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: Qwen2-Audio_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 29/35 [02:17<00:16,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: Qwen2-VL_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 30/35 [02:18<00:11,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: Qwen2.5-Omni_Technical_Report_(2025).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 31/35 [02:20<00:08,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: Qwen2.5-VL_Technical_Report_(2025).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 32/35 [02:21<00:05,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: Qwen2.5_Technical_Report_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 33/35 [02:23<00:03,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: Qwen2_Technical_Report_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 34/35 [02:26<00:02,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: Qwen3_Technical_Report_(2025).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [02:26<00:00,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted: RecurrentGemma_(2024).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pdfs = list(PDF_DIR.glob(\"*.pdf\"))\n",
    "print(f\"Found {len(pdfs)} PDFs\")\n",
    "\n",
    "for pdf in tqdm(pdfs):\n",
    "    out = RAW_TEXT_DIR / (pdf.stem + \".txt\")\n",
    "    if out.exists(): continue\n",
    "    raw = extract_pdf_text(pdf)\n",
    "    clean = basic_clean(raw)\n",
    "    out.write_text(clean, encoding=\"utf-8\")\n",
    "    print(\"Extracted:\", pdf.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60bcf7e",
   "metadata": {},
   "source": [
    "# Chunk text into segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e6cfdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jsonlines in c:\\users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages (from jsonlines) (25.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ced62bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0afeda60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35 text files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 5/35 [00:00<00:00, 38.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunked CodeGemma_(2024).txt: 16 chunks\n",
      "Chunked DeepSeek-Coder_(2024).txt: 32 chunks\n",
      "Chunked DeepSeek-R1_(2025).txt: 27 chunks\n",
      "Chunked DeepSeek-V2_(2024).txt: 63 chunks\n",
      "Chunked DeepSeek-V3_Technical_Report_(2024).txt: 70 chunks\n",
      "Chunked Gemini_1.0.txt: 94 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 12/35 [00:00<00:00, 24.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunked Gemini_1.5_(2024).txt: 182 chunks\n",
      "Chunked Gemma_(2024).txt: 25 chunks\n",
      "Chunked Gemma_2_(2024).txt: 32 chunks\n",
      "Chunked Gemma_3.txt: 38 chunks\n",
      "Chunked GLM-130B_(2022).txt: 82 chunks\n",
      "Chunked GPT-3.txt: 106 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 15/35 [00:00<00:00, 20.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunked GPT-4.txt: 121 chunks\n",
      "Chunked InternLM2_Technical_Report_(2024).txt: 72 chunks\n",
      "Chunked InternVL_2.5_(2024).txt: 102 chunks\n",
      "Chunked LLaMA_(2023).txt: 43 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 18/35 [00:00<00:00, 18.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunked Llama_2_(2023).txt: 115 chunks\n",
      "Chunked Llama_3_(2024).txt: 151 chunks\n",
      "Chunked Mistral_7B_(2023).txt: 11 chunks\n",
      "Chunked Mixtral_of_Experts_8x7B_(2024).txt: 15 chunks\n",
      "Chunked Nemotron-4_340B_Technical_Report_(2024).txt: 38 chunks\n",
      "Chunked NVLM_1.0_(2024).txt: 60 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 26/35 [00:01<00:00, 23.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunked PaLM.txt: 133 chunks\n",
      "Chunked PaLM2.txt: 122 chunks\n",
      "Chunked PanGu-Σ_(2023).txt: 61 chunks\n",
      "Chunked Phi-3_Safety_Post-Training_(2024).txt: 18 chunks\n",
      "Chunked Phi-3_Technical_Report_(2024).txt: 30 chunks\n",
      "Chunked Qwen2-Audio_(2024).txt: 17 chunks\n",
      "Chunked Qwen2-VL_(2024).txt: 54 chunks\n",
      "Chunked Qwen2.5-Omni_Technical_Report_(2025).txt: 36 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 26.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunked Qwen2.5-VL_Technical_Report_(2025).txt: 42 chunks\n",
      "Chunked Qwen2.5_Technical_Report_(2024).txt: 50 chunks\n",
      "Chunked Qwen2_Technical_Report_(2024).txt: 43 chunks\n",
      "Chunked Qwen3_Technical_Report_(2025).txt: 70 chunks\n",
      "Chunked RecurrentGemma_(2024).txt: 8 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text_files = list(RAW_TEXT_DIR.glob(\"*.txt\"))\n",
    "print(f\"Found {len(text_files)} text files\")\n",
    "\n",
    "for txt in tqdm(text_files):\n",
    "    text = txt.read_text(encoding=\"utf-8\")\n",
    "    chunks = split_into_token_chunks(text, MAX_TOKENS_PER_CHUNK, OVERLAP_TOKENS, MIN_TOKENS_PER_CHUNK)\n",
    "    out = CHUNKS_DIR / (txt.stem + \".chunks.jsonl\")\n",
    "    with jsonlines.open(out, \"w\") as w:\n",
    "        for i, ch in enumerate(chunks):\n",
    "            w.write({\"source\": txt.name, \"chunk_id\": i, \"tokens\": token_len(ch), \"text\": ch})\n",
    "    print(f\"Chunked {txt.name}: {len(chunks)} chunks\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a91f31b",
   "metadata": {},
   "source": [
    "# Triplet generation via vLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6e99c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligible papers: 34\n",
      "Per-paper targets: base=56, extra=23  → 53/54 mix\n",
      "k (triplets per chunk) = 1\n",
      "Output file → outputs\\triplets_run_llama70b_20251028_000630.jsonl\n",
      "Planned chunks to process: 1428  (cap: 1927)\n"
     ]
    },
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x2301a0b5360 state=finished raised APIConnectionError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\httpx\\_transports\\default.py:101\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\httpx\\_transports\\default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\httpcore\\_sync\\connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\httpcore\\_sync\\connection.py:78\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     ssl_object \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mget_extra_info(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssl_object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\httpcore\\_sync\\connection.py:124\u001b[0m, in \u001b[0;36mHTTPConnection._connect\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnect_tcp\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m--> 124\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_backend\u001b[38;5;241m.\u001b[39mconnect_tcp(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    125\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m stream\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\httpcore\\_backends\\sync.py:207\u001b[0m, in \u001b[0;36mSyncBackend.connect_tcp\u001b[1;34m(self, host, port, timeout, local_address, socket_options)\u001b[0m\n\u001b[0;32m    202\u001b[0m exc_map: ExceptionMapping \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    203\u001b[0m     socket\u001b[38;5;241m.\u001b[39mtimeout: ConnectTimeout,\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[0;32m    205\u001b[0m }\n\u001b[1;32m--> 207\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    208\u001b[0m     sock \u001b[38;5;241m=\u001b[39m socket\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    209\u001b[0m         address,\n\u001b[0;32m    210\u001b[0m         timeout,\n\u001b[0;32m    211\u001b[0m         source_address\u001b[38;5;241m=\u001b[39msource_address,\n\u001b[0;32m    212\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\httpcore\\_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[1;34m(map)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[1;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mConnectError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\openai\\_base_client.py:982\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 982\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    983\u001b[0m         request,\n\u001b[0;32m    984\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    986\u001b[0m     )\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\httpx\\_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\httpx\\_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\httpx\\_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    977\u001b[0m     hook(request)\n\u001b[1;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\httpx\\_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\httpx\\_transports\\default.py:249\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    248\u001b[0m )\n\u001b[1;32m--> 249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m    250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\httpx\\_transports\\default.py:118\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m    117\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mConnectError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\tenacity\\__init__.py:480\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 480\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[20], line 126\u001b[0m, in \u001b[0;36mcall_model\u001b[1;34m(chunk_text, k)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# vLLM supports Chat Completions compat\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# adjust if you need more variety\u001b[39;49;00m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# guardrail for long outputs\u001b[39;49;00m\n\u001b[0;32m    131\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m text \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\openai\\_utils\\_utils.py:286\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1156\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m   1155\u001b[0m validate_response_format(response_format)\n\u001b[1;32m-> 1156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1162\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1163\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1164\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1166\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1167\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1168\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1169\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1170\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1171\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1172\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1173\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1174\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1179\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafety_identifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1184\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1185\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1186\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1187\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1188\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1189\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1190\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbosity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[0;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[0;32m   1197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\openai\\_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1256\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1257\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1258\u001b[0m )\n\u001b[1;32m-> 1259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\openai\\_base_client.py:1014\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP Response: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1018\u001b[0m     request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     response\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m   1023\u001b[0m )\n",
      "\u001b[1;31mAPIConnectionError\u001b[0m: Connection error.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 167\u001b[0m\n\u001b[0;32m    164\u001b[0m     futures\u001b[38;5;241m.\u001b[39mappend(fut)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fut \u001b[38;5;129;01min\u001b[39;00m as_completed(futures):\n\u001b[1;32m--> 167\u001b[0m     triplets \u001b[38;5;241m=\u001b[39m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m     recs \u001b[38;5;241m=\u001b[39m make_records(fut\u001b[38;5;241m.\u001b[39mmeta_chunk, triplets)\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m rec \u001b[38;5;129;01min\u001b[39;00m recs:\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\tenacity\\__init__.py:338\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    336\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    337\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copy(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\tenacity\\__init__.py:477\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 477\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\tenacity\\__init__.py:378\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    376\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\cuda_test\\lib\\site-packages\\tenacity\\__init__.py:421\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[1;32m--> 421\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "\u001b[1;31mRetryError\u001b[0m: RetryError[<Future at 0x2301a0b5360 state=finished raised APIConnectionError>]"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Llama-3-70B triplet generation via vLLM (OpenAI-compatible)\n",
    "# ============================================\n",
    "import os, json, math, random, time, collections, datetime\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import jsonlines\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential_jitter\n",
    "\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "except Exception:\n",
    "    !pip -q install openai==1.51.2\n",
    "    from openai import OpenAI\n",
    "\n",
    "# -----------------------\n",
    "# CONFIG\n",
    "# -----------------------\n",
    "# Local vLLM server (started in step 1)\n",
    "BASE_URL   = \"http://127.0.0.1:8000/v1\"\n",
    "API_KEY    = \"EMPTY\"  # vLLM ignores, but the client expects a string\n",
    "MODEL_NAME = \"TheBloke/Llama-3-70B-Instruct-GPTQ\"   # same as you passed to vLLM; or --served-model-name\n",
    "\n",
    "# Target accounting (you already produced 73 from InternVL)\n",
    "TARGET_TOTAL = 2000\n",
    "ALREADY_HAVE = 73\n",
    "REMAINING    = TARGET_TOTAL - ALREADY_HAVE  # 1927\n",
    "\n",
    "# Papers to skip this run\n",
    "SKIP_SUBSTRINGS = [\"InternVL\"]\n",
    "\n",
    "# Concurrency\n",
    "MAX_WORKERS = 8\n",
    "RNG_SEED    = 13\n",
    "random.seed(RNG_SEED)\n",
    "\n",
    "# Triplet policy (per chunk)\n",
    "N_TRIPLETS_PER_CHUNK = 1           # predictable volume & cost\n",
    "\n",
    "# Paths (adjust if needed)\n",
    "CHUNKS_DIR = Path(\"data/chunks\")   # folder with *.chunks.jsonl created earlier\n",
    "OUT_DIR    = Path(\"outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Output file for this run\n",
    "ts = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "triplets_path = OUT_DIR / f\"triplets_run_llama70b_{ts}.jsonl\"\n",
    "\n",
    "# Prompts (same structure as your GPT-5 pipeline)\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a meticulous data constructor. Given a technical passage (CHUNK), \"\n",
    "    \"produce instruction-tuning triplets that are useful for training. \"\n",
    "    \"Prefer concrete, unambiguous, domain-grounded questions.\"\n",
    ")\n",
    "GEN_PROMPT = (\n",
    "    \"You will receive a technical passage (CHUNK). Produce {k} high-quality instruction-tuning triplets.\\n\"\n",
    "    'Each triplet is a JSON object with fields: \"question\", \"input\", \"response\".\\n'\n",
    "    \"Return a JSON array of triplets only.\"\n",
    ")\n",
    "\n",
    "# OpenAI-compatible client pointed at vLLM\n",
    "client = OpenAI(base_url=BASE_URL, api_key=API_KEY)\n",
    "\n",
    "# -----------------------\n",
    "# DISCOVER ELIGIBLE PAPERS\n",
    "# -----------------------\n",
    "def skip_file(p: Path) -> bool:\n",
    "    name = p.name.lower()\n",
    "    return any(s.lower() in name for s in SKIP_SUBSTRINGS)\n",
    "\n",
    "chunk_files = sorted(CHUNKS_DIR.glob(\"*.chunks.jsonl\"))\n",
    "eligible_files = [p for p in chunk_files if not skip_file(p)]\n",
    "assert eligible_files, \"No eligible papers after applying SKIP_SUBSTRINGS.\"\n",
    "\n",
    "num_papers = len(eligible_files)   # should be 36 for you\n",
    "base = REMAINING // num_papers\n",
    "extra = REMAINING - base * num_papers  # first 'extra' papers get +1\n",
    "per_paper_targets = {p: base for p in eligible_files}\n",
    "for p in eligible_files[:extra]:\n",
    "    per_paper_targets[p] += 1\n",
    "\n",
    "print(f\"Eligible papers: {num_papers}\")\n",
    "print(f\"Per-paper targets: base={base}, extra={extra}  → 53/54 mix\")\n",
    "print(f\"k (triplets per chunk) = {N_TRIPLETS_PER_CHUNK}\")\n",
    "print(f\"Output file → {triplets_path}\")\n",
    "\n",
    "# -----------------------\n",
    "# READ CHUNKS & BUILD WORK\n",
    "# -----------------------\n",
    "def read_chunks(file_path: Path):\n",
    "    rows = []\n",
    "    with jsonlines.open(file_path, \"r\") as r:\n",
    "        for obj in r:\n",
    "            rows.append(obj)\n",
    "    return rows\n",
    "\n",
    "work = []  # list[(paper_path, chunk_obj)]\n",
    "for cf in eligible_files:\n",
    "    need_triplets = per_paper_targets[cf]                 # 53 or 54\n",
    "    need_chunks   = math.ceil(need_triplets / N_TRIPLETS_PER_CHUNK)\n",
    "    rows = read_chunks(cf)\n",
    "    chosen = rows if len(rows) <= need_chunks else random.sample(rows, need_chunks)\n",
    "    for obj in chosen:\n",
    "        work.append((cf, obj))\n",
    "\n",
    "# cap by theoretical max chunk need\n",
    "max_chunks_needed = math.ceil(REMAINING / N_TRIPLETS_PER_CHUNK)\n",
    "if len(work) > max_chunks_needed:\n",
    "    work = work[:max_chunks_needed]\n",
    "\n",
    "print(f\"Planned chunks to process: {len(work)}  (cap: {max_chunks_needed})\")\n",
    "\n",
    "# -----------------------\n",
    "# MODEL CALL (with retry)\n",
    "# -----------------------\n",
    "@retry(stop=stop_after_attempt(4), wait=wait_exponential_jitter(initial=1, max=8))\n",
    "def call_model(chunk_text: str, k: int):\n",
    "    user_prompt = f\"CHUNK:\\n\\n{chunk_text}\\n\\n---\\nPlease output exactly a JSON array of {k} triplets.\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\",   \"content\": GEN_PROMPT.format(k=k)},\n",
    "        {\"role\": \"user\",   \"content\": user_prompt},\n",
    "    ]\n",
    "    # vLLM supports Chat Completions compat\n",
    "    resp = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "        temperature=0.2,          # adjust if you need more variety\n",
    "        max_tokens=800,           # guardrail for long outputs\n",
    "    )\n",
    "    text = resp.choices[0].message.content\n",
    "    try:\n",
    "        data = json.loads(text)\n",
    "        return data if isinstance(data, list) else []\n",
    "    except Exception:\n",
    "        # Be permissive: if malformed, return empty instead of failing the batch\n",
    "        return []\n",
    "\n",
    "def make_records(meta_chunk_obj, triplets_list):\n",
    "    out = []\n",
    "    for t in triplets_list:\n",
    "        rec = {\n",
    "            \"question\": (t.get(\"question\") or \"\").strip(),\n",
    "            \"input\":     t.get(\"input\", \"\"),\n",
    "            \"response\": (t.get(\"response\") or \"\").strip(),\n",
    "            \"meta\": meta_chunk_obj,  # carries source, chunk_id, tokens, etc.\n",
    "        }\n",
    "        if rec[\"question\"] and rec[\"response\"]:\n",
    "            out.append(rec)\n",
    "    return out\n",
    "\n",
    "# -----------------------\n",
    "# PARALLEL EXECUTION (single writer)\n",
    "# -----------------------\n",
    "written = 0\n",
    "per_source_written = collections.Counter()\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex, jsonlines.open(triplets_path, \"a\") as w:\n",
    "    futures = []\n",
    "    for (src_path, chunk_obj) in work:\n",
    "        fut = ex.submit(call_model, chunk_obj[\"text\"], N_TRIPLETS_PER_CHUNK)\n",
    "        fut.meta_chunk = chunk_obj\n",
    "        futures.append(fut)\n",
    "\n",
    "    for fut in as_completed(futures):\n",
    "        triplets = fut.result()\n",
    "        recs = make_records(fut.meta_chunk, triplets)\n",
    "        for rec in recs:\n",
    "            if written >= REMAINING:\n",
    "                break\n",
    "            w.write(rec)  # single writer (main thread) → no file corruption\n",
    "            written += 1\n",
    "            per_source_written[rec[\"meta\"][\"source\"]] += 1\n",
    "        if written >= REMAINING:\n",
    "            break\n",
    "\n",
    "print(f\"[DONE] Wrote {written} triplets → {triplets_path}\")\n",
    "print(\"Per-paper tally (top 10):\")\n",
    "for k, v in per_source_written.most_common(10):\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(\"Total papers written:\", len(per_source_written))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a673dc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
